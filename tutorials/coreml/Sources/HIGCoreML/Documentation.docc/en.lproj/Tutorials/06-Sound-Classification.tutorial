@Tutorial(time: 20) {
    @Intro(title: "Sound Classification") {
        Build an app that analyzes microphone input in real-time
        to recognize different types of sounds.
    }
    
    @Section(title: "Sound Analysis Framework") {
        @ContentAndMedia {
            The **SoundAnalysis** framework provides functionality
            to analyze audio streams in real-time.
            
            Capture audio with AVFoundation
            and classify with SNClassifySoundRequest.
        }
        
        @Steps {
            @Step {
                **Using Apple's Built-in Sound Classifier**
                
                You can use Apple's built-in classifier
                that recognizes 300+ different sounds.
                
                @Code(name: "BuiltInClassifier.swift", file: "06-builtin-classifier.swift")
            }
            
            @Step {
                **Creating SNClassifySoundRequest**
                
                Create a classification request and
                specify the sound categories you're interested in.
                
                @Code(name: "SoundRequest.swift", file: "06-sound-request.swift")
            }
            
            @Step {
                **Results Observer**
                
                Implement the SNResultsObserving protocol
                to handle classification results.
                
                @Code(name: "ResultsObserver.swift", file: "06-results-observer.swift")
            }
        }
    }
    
    @Section(title: "Real-time Audio Analysis") {
        @ContentAndMedia {
            Capture microphone input with AVAudioEngine
            and classify sounds in real-time.
        }
        
        @Steps {
            @Step {
                **Setting up AVAudioEngine**
                
                Tap the microphone input to prepare
                audio for SoundAnalysis.
                
                @Code(name: "AudioEngineSetup.swift", file: "06-audio-engine.swift")
            }
            
            @Step {
                **Using SNAudioStreamAnalyzer**
                
                Set up an Analyzer to analyze
                real-time audio streams.
                
                @Code(name: "StreamAnalyzer.swift", file: "06-stream-analyzer.swift")
            }
            
            @Step {
                **Requesting Microphone Permission**
                
                Add microphone usage description to Info.plist
                and request permission.
                
                @Code(name: "MicrophonePermission.swift", file: "06-mic-permission.swift")
            }
            
            @Step {
                **Complete SoundClassifier Service**
                
                Complete an integrated service
                from audio capture to classification.
                
                @Code(name: "SoundClassifier.swift", file: "06-sound-classifier.swift")
            }
        }
    }
    
    @Section(title: "Custom Sound Classifier") {
        @ContentAndMedia {
            Train your own sound classifier with Create ML.
            Recognize specific sounds like alarms or doorbells.
        }
        
        @Steps {
            @Step {
                **Collecting Audio Data**
                
                Collect sound samples organized by folder.
                At least 100 samples per class is recommended.
                
                @Code(name: "AudioDataCollection.swift", file: "06-audio-data.swift")
            }
            
            @Step {
                **Create ML Sound Classification**
                
                Train a custom classifier using
                the Sound Classification template.
                
                @Code(name: "SoundTraining.swift", file: "06-sound-training.swift")
            }
            
            @Step {
                **Applying Custom Model**
                
                Apply the trained .mlmodel to your app
                to recognize custom sounds.
                
                @Code(name: "CustomSoundModel.swift", file: "06-custom-model.swift")
            }
        }
    }
    
    @Section(title: "Sound Classification UI") {
        @ContentAndMedia {
            Implement a UI that visually displays
            real-time classification results.
        }
        
        @Steps {
            @Step {
                **Real-time Classification View**
                
                Display the currently detected sound
                and confidence with a gauge.
                
                @Code(name: "SoundClassificationView.swift", file: "06-classification-view.swift")
            }
            
            @Step {
                **Sound History Display**
                
                Show a timeline list of
                recently detected sounds.
                
                @Code(name: "SoundHistory.swift", file: "06-sound-history.swift")
            }
        }
    }
    
    @Assessments {
        @MultipleChoice {
            Approximately how many types of sounds can Apple's built-in sound classifier recognize?
            
            @Choice(isCorrect: true) {
                300 or more
                
                @Justification(reaction: "Correct!") {
                    Apple's built-in classifier recognizes music, animal sounds,
                    appliance sounds, and 300+ other types.
                }
            }
            
            @Choice(isCorrect: false) {
                Less than 50
                
                @Justification(reaction: "Not quite") {
                    Apple's built-in classifier can recognize
                    300+ different sounds.
                }
            }
            
            @Choice(isCorrect: false) {
                Developer must define manually
                
                @Justification(reaction: "Not quite") {
                    Apple provides a pre-trained classifier.
                    You can also create custom classifiers as needed.
                }
            }
        }
        
        @MultipleChoice {
            What Apple framework combination is used for real-time audio analysis?
            
            @Choice(isCorrect: true) {
                AVFoundation + SoundAnalysis
                
                @Justification(reaction: "That's right!") {
                    AVFoundation captures audio and
                    SoundAnalysis classifies it.
                }
            }
            
            @Choice(isCorrect: false) {
                Vision + Core ML
                
                @Justification(reaction: "Not quite") {
                    Vision is for image processing.
                    Audio uses AVFoundation + SoundAnalysis.
                }
            }
            
            @Choice(isCorrect: false) {
                AudioKit + Core ML
                
                @Justification(reaction: "Not quite") {
                    AudioKit is a third-party library.
                    Apple's official approach is AVFoundation + SoundAnalysis.
                }
            }
        }
    }
}
