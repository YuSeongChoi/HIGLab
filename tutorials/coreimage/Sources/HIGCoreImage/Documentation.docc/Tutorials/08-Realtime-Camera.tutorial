@Tutorial(time: 30) {
    @Intro(title: "실시간 카메라 필터") {
        AVFoundation과 CoreImage를 연동하여 
        실시간 카메라 필터를 구현하는 방법을 학습합니다.
        
        @Image(source: "realtime-camera.png", alt: "실시간 카메라")
    }
    
    @Section(title: "AVCaptureSession 설정") {
        @ContentAndMedia {
            카메라 필터 앱의 기반이 되는 AVCaptureSession을 구성합니다.
            비디오 입력과 출력을 설정하고 프레임을 받을 준비를 합니다.
            
            구성 요소:
            - **AVCaptureSession**: 캡처 세션 관리
            - **AVCaptureDeviceInput**: 카메라 입력
            - **AVCaptureVideoDataOutput**: 비디오 프레임 출력
            - **AVCaptureVideoPreviewLayer**: 프리뷰 레이어
            
            @Image(source: "capture-session.png", alt: "캡처 세션 구성")
        }
        
        @Steps {
            @Step {
                기본 AVCaptureSession을 구성합니다.
                카메라 입력과 비디오 데이터 출력을 연결합니다.
                
                @Code(name: "CaptureSession.swift", file: "08-01-capture-session.swift")
            }
            
            @Step {
                AVCaptureVideoDataOutputSampleBufferDelegate를 구현합니다.
                매 프레임마다 호출되는 델리게이트 메서드를 설정합니다.
                
                @Code(name: "SampleBufferDelegate.swift", file: "08-02-sample-buffer-delegate.swift")
            }
            
            @Step {
                CMSampleBuffer에서 CIImage를 추출합니다.
                CVPixelBuffer를 통해 효율적으로 변환합니다.
                
                @Code(name: "ExtractCIImage.swift", file: "08-03-extract-ciimage.swift")
            }
        }
    }
    
    @Section(title: "실시간 필터 적용") {
        @ContentAndMedia {
            카메라 프레임에 실시간으로 필터를 적용합니다.
            30fps 이상을 유지하려면 성능 최적화가 필수입니다.
            
            최적화 포인트:
            - CIContext 재사용
            - 메인 스레드 차단 금지
            - 적절한 이미지 해상도 선택
            - 비동기 렌더링
        }
        
        @Steps {
            @Step {
                CIContext를 한 번만 생성하고 재사용합니다.
                Metal 기반 컨텍스트로 GPU 가속을 활용합니다.
                
                @Code(name: "ReusableContext.swift", file: "08-04-reusable-context.swift")
            }
            
            @Step {
                프레임에 필터를 적용하고 렌더링합니다.
                백그라운드 스레드에서 처리해 UI를 차단하지 않습니다.
                
                @Code(name: "ApplyFilter.swift", file: "08-05-apply-filter.swift")
            }
            
            @Step {
                렌더링된 이미지를 화면에 표시합니다.
                MTKView 또는 CALayer를 사용해 효율적으로 표시합니다.
                
                @Code(name: "DisplayFiltered.swift", file: "08-06-display-filtered.swift")
            }
        }
    }
    
    @Section(title: "Metal 기반 실시간 렌더링") {
        @ContentAndMedia {
            MTKView를 사용하면 Metal 파이프라인으로 
            최적의 성능으로 필터를 표시할 수 있습니다.
            
            장점:
            - VSync 동기화
            - Metal 텍스처 직접 렌더링
            - 최소 지연시간
            - 프레임 드롭 최소화
        }
        
        @Steps {
            @Step {
                MTKView를 설정하고 CIContext와 연동합니다.
                Metal 디바이스와 커맨드 큐를 공유합니다.
                
                @Code(name: "MTKViewSetup.swift", file: "08-07-mtkview-setup.swift")
            }
            
            @Step {
                MTKViewDelegate의 draw 메서드에서 렌더링합니다.
                현재 드로어블에 CIImage를 렌더링합니다.
                
                @Code(name: "MTKViewDraw.swift", file: "08-08-mtkview-draw.swift")
            }
            
            @Step {
                프레임 동기화를 구현합니다.
                카메라 프레임과 디스플레이 리프레시를 맞춥니다.
                
                @Code(name: "FrameSync.swift", file: "08-09-frame-sync.swift")
            }
        }
    }
    
    @Section(title: "SwiftUI 통합") {
        @ContentAndMedia {
            SwiftUI에서 실시간 카메라 필터 뷰를 사용합니다.
            UIViewRepresentable로 MTKView를 래핑합니다.
            
            구현 사항:
            - UIViewRepresentable로 뷰 래핑
            - @StateObject로 카메라 매니저 관리
            - Combine으로 필터 변경 반응형 처리
        }
        
        @Steps {
            @Step {
                카메라 매니저를 ObservableObject로 구현합니다.
                세션 관리와 필터 적용을 캡슐화합니다.
                
                @Code(name: "CameraManager.swift", file: "08-10-camera-manager.swift")
            }
            
            @Step {
                MTKView를 UIViewRepresentable로 래핑합니다.
                SwiftUI에서 Metal 뷰를 사용할 수 있게 합니다.
                
                @Code(name: "CameraPreviewView.swift", file: "08-11-camera-preview-view.swift")
            }
            
            @Step {
                필터 선택 UI를 SwiftUI로 구현합니다.
                실시간으로 필터가 변경되는 것을 확인합니다.
                
                @Code(name: "FilterSelectionView.swift", file: "08-12-filter-selection-view.swift")
            }
            
            @Step {
                사진 촬영 기능을 추가합니다.
                현재 필터가 적용된 상태로 사진을 저장합니다.
                
                @Code(name: "CapturePhoto.swift", file: "08-13-capture-photo.swift")
            }
        }
    }
    
    @Assessments {
        @MultipleChoice {
            실시간 카메라 필터에서 CIContext를 재사용해야 하는 이유는?
            
            @Choice(isCorrect: true) {
                CIContext 생성 비용이 높아 매 프레임 생성하면 성능이 저하된다.
                
                @Justification(reaction: "정확합니다! 🎯") {
                    CIContext는 GPU 리소스를 할당하므로 
                    한 번 생성해서 재사용해야 합니다.
                }
            }
            
            @Choice(isCorrect: false) {
                CIContext는 한 번만 생성할 수 있기 때문
                
                @Justification(reaction: "그렇지 않습니다.") {
                    여러 개 생성 가능하지만 비효율적입니다.
                }
            }
            
            @Choice(isCorrect: false) {
                메모리 누수를 방지하기 위해
                
                @Justification(reaction: "주요 이유가 아닙니다.") {
                    성능 최적화가 핵심 이유입니다.
                }
            }
        }
        
        @MultipleChoice {
            AVCaptureVideoDataOutput에서 프레임을 받을 때 주의할 점은?
            
            @Choice(isCorrect: true) {
                델리게이트 콜백은 지정한 큐에서 호출되므로 UI 업데이트 시 메인 큐 사용
                
                @Justification(reaction: "맞습니다! ✨") {
                    비디오 프레임 처리는 백그라운드에서 하고,
                    UI 업데이트만 메인 스레드로 전달합니다.
                }
            }
            
            @Choice(isCorrect: false) {
                프레임은 항상 메인 스레드에서 전달된다
                
                @Justification(reaction: "그렇지 않습니다.") {
                    sampleBufferCallbackQueue로 지정한 큐에서 호출됩니다.
                }
            }
            
            @Choice(isCorrect: false) {
                프레임 버퍼는 자동으로 복사되므로 오래 보관해도 된다
                
                @Justification(reaction: "주의가 필요합니다.") {
                    버퍼 풀 고갈을 막으려면 빠르게 처리하고 해제해야 합니다.
                }
            }
        }
        
        @MultipleChoice {
            MTKView를 사용한 카메라 프리뷰의 장점은?
            
            @Choice(isCorrect: true) {
                Metal 파이프라인으로 최소 지연시간과 VSync 동기화 제공
                
                @Justification(reaction: "정확합니다! 🎯") {
                    MTKView는 디스플레이 리프레시와 동기화되어 
                    프레임 드롭을 최소화합니다.
                }
            }
            
            @Choice(isCorrect: false) {
                자동으로 얼굴을 감지한다
                
                @Justification(reaction: "관련이 없습니다.") {
                    얼굴 감지는 별도로 구현해야 합니다.
                }
            }
            
            @Choice(isCorrect: false) {
                UIImageView보다 메모리를 더 많이 사용한다
                
                @Justification(reaction: "오히려 효율적입니다.") {
                    텍스처를 직접 렌더링해 메모리 복사를 줄입니다.
                }
            }
        }
    }
}
