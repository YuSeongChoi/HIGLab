<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1">
<title>ğŸ‘ï¸â€ğŸ—¨ï¸ Vision í”„ë ˆì„ì›Œí¬ â€” HIG Lab</title>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;700;900&family=JetBrains+Mono&display=swap" rel="stylesheet">
<style>
:root{--bg:#fafafa;--text:#1d1d1f;--text-2:#6e6e73;--accent:#0071e3;--code-bg:#1e1e2e;--border:#d2d2d7}
*{margin:0;padding:0;box-sizing:border-box}body{font-family:'Inter',sans-serif;background:var(--bg);color:var(--text);line-height:1.8}
.top-bar{position:sticky;top:0;z-index:100;background:rgba(250,250,250,0.9);backdrop-filter:blur(20px);border-bottom:1px solid var(--border)}
.top-bar-inner{max-width:800px;margin:0 auto;padding:12px 24px;display:flex;justify-content:space-between}
.top-logo{font-size:16px;font-weight:700;text-decoration:none;color:var(--text)}.top-logo span{color:var(--accent)}
article{max-width:800px;margin:0 auto;padding:48px 24px 120px}
h1{font-size:clamp(28px,5vw,40px);font-weight:900;margin-bottom:16px;letter-spacing:-1px}
h2{font-size:24px;font-weight:800;margin:48px 0 16px}p{margin-bottom:16px}
.subtitle{font-size:18px;color:var(--text-2);margin-bottom:32px}
.code-block{background:var(--code-bg);border-radius:12px;margin:20px 0;overflow:hidden}
.code-header{padding:12px 16px;border-bottom:1px solid rgba(255,255,255,0.1);font-size:12px;color:#6e6e73;font-weight:600}
pre.code-body{margin:0;padding:16px;font-family:'JetBrains Mono',monospace;font-size:13px;color:#cdd6f4;white-space:pre;overflow-x:auto}
.kw{color:#cba6f7}.type{color:#89b4fa}.str{color:#a6e3a1}.comment{color:#6c7086}
.badge{display:inline-block;padding:4px 12px;border-radius:16px;font-size:13px;font-weight:600;margin:0 4px 8px 0}
.badge.ios{background:#0071e3;color:#fff}.badge.new{background:#34c759;color:#fff}
ul{margin:16px 0 16px 24px}li{margin:8px 0}
.info-box{background:#f5f5f7;border-left:4px solid var(--accent);padding:16px;margin:24px 0;border-radius:8px}
</style></head>
<body>
<div class="top-bar"><div class="top-bar-inner"><a href="../index.html" class="top-logo">HIG <span>Lab</span></a><a href="01-tutorial.html" class="lang-toggle" style="font-size:12px;font-weight:600;color:#0071e3;text-decoration:none;padding:4px 10px;border:1.5px solid #0071e3;border-radius:12px;">ğŸŒ KO</a></div></div>
<article>
<h1>ğŸ‘ï¸â€ğŸ—¨ï¸ Vision í”„ë ˆì„ì›Œí¬</h1>
<p class="subtitle">ì»´í“¨í„° ë¹„ì „ìœ¼ë¡œ ì´ë¯¸ì§€ì™€ ë¹„ë””ì˜¤ ë¶„ì„í•˜ê¸°</p>

<div><span class="badge ios">iOS 11+</span><span class="badge new">visionOS Supported</span></div>

<h2>âœ¨ Vision is?</h2>
<p>Vision is Apple's computer vision framework, providing powerful image/video analysis features including face detection, text recognition, barcode scanning, and object tracking. It integrates with Core ML to run custom machine learning models.</p>

<div class="info-box">
<strong>ğŸ’¡ Key Features:</strong> Face/Body Detection Â· Text Recognition (OCR) Â· Barcode Scanning Â· Object Tracking Â· Contour Detection Â· Image Alignment Â· Core ML Integration
</div>

<h2>ğŸ¯ 1. ì–¼êµ´ ì¸ì‹ (Face Detection)</h2>
<p>Find faces in images and detect landmarks (eyes, nose, mouth, etc.).</p>

<div class="code-block">
<div class="code-header">FaceDetector.swift â€” ì–¼êµ´ ì¸ì‹</div>
<pre class="code-body"><span class="kw">import</span> <span class="type">Vision</span>
<span class="kw">import</span> <span class="type">UIKit</span>

<span class="kw">@Observable</span>
<span class="kw">class</span> <span class="type">FaceDetector</span> {
    <span class="kw">var</span> detectedFaces: [<span class="type">VNFaceObservation</span>] = []
    <span class="kw">var</span> isProcessing = <span class="kw">false</span>
    <span class="kw">var</span> errorMessage: <span class="type">String</span>?

    <span class="kw">func</span> detectFaces(in image: <span class="type">UIImage</span>) <span class="kw">async</span> {
        isProcessing = <span class="kw">true</span>
        errorMessage = <span class="kw">nil</span>

        <span class="kw">guard</span> <span class="kw">let</span> cgImage = image.cgImage <span class="kw">else</span> {
            errorMessage = <span class="str">"ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨"</span>
            isProcessing = <span class="kw">false</span>
            <span class="kw">return</span>
        }

        <span class="comment">// Face detection request</span>
        <span class="kw">let</span> request = <span class="type">VNDetectFaceRectanglesRequest</span> { [<span class="kw">weak self</span>] request, error <span class="kw">in</span>
            <span class="kw">guard</span> <span class="kw">let</span> observations = request.results <span class="kw">as</span>? [<span class="type">VNFaceObservation</span>] <span class="kw">else</span> {
                <span class="kw">self</span>?.errorMessage = error?.localizedDescription ?? <span class="str">"ì–¼êµ´ ê²€ì¶œ ì‹¤íŒ¨"</span>
                <span class="kw">return</span>
            }
            <span class="kw">self</span>?.detectedFaces = observations
        }

        <span class="comment">// Perform request</span>
        <span class="kw">let</span> handler = <span class="type">VNImageRequestHandler</span>(cgImage: cgImage, options: [:])
        <span class="kw">do</span> {
            <span class="kw">try</span> handler.perform([request])
        } <span class="kw">catch</span> {
            errorMessage = error.localizedDescription
        }

        isProcessing = <span class="kw">false</span>
    }

    <span class="comment">// ì–¼êµ´ ëœë“œë§ˆí¬ ê²€ì¶œ (ëˆˆ, ì½”, ì… ë“±)</span>
    <span class="kw">func</span> detectFaceLandmarks(in image: <span class="type">UIImage</span>) <span class="kw">async</span> -> [<span class="type">VNFaceObservation</span>]? {
        <span class="kw">guard</span> <span class="kw">let</span> cgImage = image.cgImage <span class="kw">else</span> { <span class="kw">return</span> <span class="kw">nil</span> }

        <span class="kw">let</span> request = <span class="type">VNDetectFaceLandmarksRequest</span>()
        <span class="kw">let</span> handler = <span class="type">VNImageRequestHandler</span>(cgImage: cgImage)

        <span class="kw">try</span>? handler.perform([request])
        <span class="kw">return</span> request.results <span class="kw">as</span>? [<span class="type">VNFaceObservation</span>]
    }
}</pre>
</div>

<div class="code-block">
<div class="code-header">FaceDetectionView.swift â€” SwiftUI Integration</div>
<pre class="code-body"><span class="kw">import</span> <span class="type">SwiftUI</span>

<span class="kw">struct</span> <span class="type">FaceDetectionView</span>: <span class="type">View</span> {
    <span class="kw">@State</span> <span class="kw">private</span> <span class="kw">var</span> detector = <span class="type">FaceDetector</span>()
    <span class="kw">@State</span> <span class="kw">private</span> <span class="kw">var</span> selectedImage: <span class="type">UIImage</span>?
    <span class="kw">@State</span> <span class="kw">private</span> <span class="kw">var</span> showImagePicker = <span class="kw">false</span>

    <span class="kw">var</span> body: <span class="kw">some</span> <span class="type">View</span> {
        <span class="type">VStack</span>(spacing: <span class="str">20</span>) {
            <span class="kw">if</span> <span class="kw">let</span> image = selectedImage {
                <span class="type">Image</span>(uiImage: image)
                    .resizable()
                    .scaledToFit()
                    .frame(height: <span class="str">300</span>)
                    .overlay {
                        <span class="comment">// ì–¼êµ´ ìœ„ì¹˜ì— ì‚¬ê°í˜• í‘œì‹œ</span>
                        <span class="type">GeometryReader</span> { geo <span class="kw">in</span>
                            <span class="type">ForEach</span>(detector.detectedFaces.indices, id: \.<span class="kw">self</span>) { index <span class="kw">in</span>
                                <span class="kw">let</span> face = detector.detectedFaces[index]
                                <span class="kw">let</span> boundingBox = face.boundingBox

                                <span class="type">Rectangle</span>()
                                    .stroke(<span class="type">Color</span>.green, lineWidth: <span class="str">3</span>)
                                    .frame(
                                        width: boundingBox.width * geo.size.width,
                                        height: boundingBox.height * geo.size.height
                                    )
                                    .position(
                                        x: boundingBox.midX * geo.size.width,
                                        y: (<span class="str">1</span> - boundingBox.midY) * geo.size.height
                                    )
                            }
                        }
                    }

                <span class="type">Text</span>(<span class="str">"ê²€ì¶œëœ ì–¼êµ´: \(detector.detectedFaces.count)ê°œ"</span>)
                    .font(.headline)
            }

            <span class="type">Button</span>(<span class="str">"ì‚¬ì§„ ì„ íƒ"</span>) {
                showImagePicker = <span class="kw">true</span>
            }
            .buttonStyle(.borderedProminent)

            <span class="kw">if</span> detector.isProcessing {
                <span class="type">ProgressView</span>(<span class="str">"ì–¼êµ´ ê²€ì¶œ ì¤‘..."</span>)
            }

            <span class="kw">if</span> <span class="kw">let</span> error = detector.errorMessage {
                <span class="type">Text</span>(error)
                    .foregroundStyle(.red)
            }
        }
        .padding()
        .sheet(isPresented: $showImagePicker) {
            <span class="type">ImagePicker</span>(image: $selectedImage)
        }
        .onChange(of: selectedImage) { _, newImage <span class="kw">in</span>
            <span class="kw">if</span> <span class="kw">let</span> image = newImage {
                <span class="type">Task</span> {
                    <span class="kw">await</span> detector.detectFaces(in: image)
                }
            }
        }
    }
}</pre>
</div>

<h2>ğŸ“ 2. í…ìŠ¤íŠ¸ ì¸ì‹ (OCR)</h2>
<p>Automatically detect and recognize text in images. Multi-language supported.</p>

<div class="code-block">
<div class="code-header">TextRecognizer.swift â€” OCR Implementation</div>
<pre class="code-body"><span class="kw">import</span> <span class="type">Vision</span>

<span class="kw">@Observable</span>
<span class="kw">class</span> <span class="type">TextRecognizer</span> {
    <span class="kw">var</span> recognizedText: <span class="type">String</span> = <span class="str">""</span>
    <span class="kw">var</span> textObservations: [<span class="type">VNRecognizedTextObservation</span>] = []

    <span class="kw">func</span> recognizeText(in image: <span class="type">UIImage</span>) <span class="kw">async</span> {
        <span class="kw">guard</span> <span class="kw">let</span> cgImage = image.cgImage <span class="kw">else</span> { <span class="kw">return</span> }

        <span class="kw">let</span> request = <span class="type">VNRecognizeTextRequest</span> { [<span class="kw">weak self</span>] request, error <span class="kw">in</span>
            <span class="kw">guard</span> <span class="kw">let</span> observations = request.results <span class="kw">as</span>? [<span class="type">VNRecognizedTextObservation</span>] <span class="kw">else</span> {
                <span class="kw">return</span>
            }

            <span class="kw">self</span>?.textObservations = observations

            <span class="comment">// ì¸ì‹ëœ ëª¨ë“  í…ìŠ¤íŠ¸ ê²°í•©</span>
            <span class="kw">let</span> recognizedStrings = observations.compactMap { observation <span class="kw">in</span>
                observation.topCandidates(<span class="str">1</span>).first?.string
            }

            <span class="kw">self</span>?.recognizedText = recognizedStrings.joined(separator: <span class="str">"\n"</span>)
        }

        <span class="comment">// ì¸ì‹ ë ˆë²¨ ì„¤ì • (accurate = ì •í™•ë„ ìš°ì„ , fast = ì†ë„ ìš°ì„ )</span>
        request.recognitionLevel = .accurate

        <span class="comment">// ë‹¤êµ­ì–´ ì§€ì› (í•œêµ­ì–´, ì˜ì–´ ë“±)</span>
        request.recognitionLanguages = [<span class="str">"ko-KR"</span>, <span class="str">"en-US"</span>]

        <span class="comment">// ì»¤ìŠ¤í…€ ë‹¨ì–´ ì¶”ê°€ (íŠ¹ì • ìš©ì–´ ì¸ì‹ë¥  í–¥ìƒ)</span>
        request.customWords = [<span class="str">"SwiftUI"</span>, <span class="str">"Vision"</span>, <span class="str">"iOS"</span>]

        <span class="kw">let</span> handler = <span class="type">VNImageRequestHandler</span>(cgImage: cgImage, options: [:])
        <span class="kw">try</span>? handler.perform([request])
    }

    <span class="comment">// íŠ¹ì • ì˜ì—­ì˜ í…ìŠ¤íŠ¸ë§Œ ì¸ì‹</span>
    <span class="kw">func</span> recognizeText(in image: <span class="type">UIImage</span>, region: <span class="type">CGRect</span>) <span class="kw">async</span> -> <span class="type">String</span>? {
        <span class="kw">guard</span> <span class="kw">let</span> cgImage = image.cgImage <span class="kw">else</span> { <span class="kw">return</span> <span class="kw">nil</span> }

        <span class="kw">let</span> request = <span class="type">VNRecognizeTextRequest</span>()
        request.regionOfInterest = region

        <span class="kw">let</span> handler = <span class="type">VNImageRequestHandler</span>(cgImage: cgImage)
        <span class="kw">try</span>? handler.perform([request])

        <span class="kw">return</span> request.results?.first?.topCandidates(<span class="str">1</span>).first?.string
    }
}</pre>
</div>

<h2>ğŸ“· 3. ë°”ì½”ë“œ/QR ì½”ë“œ ìŠ¤ìº”</h2>
<p>Recognize barcodes and QR codes from images or real-time camera.</p>

<div class="code-block">
<div class="code-header">BarcodeScanner.swift â€” Barcode Scanning</div>
<pre class="code-body"><span class="kw">import</span> <span class="type">Vision</span>
<span class="kw">import</span> <span class="type">AVFoundation</span>

<span class="kw">@Observable</span>
<span class="kw">class</span> <span class="type">BarcodeScanner</span> {
    <span class="kw">var</span> detectedCodes: [<span class="type">VNBarcodeObservation</span>] = []

    <span class="kw">func</span> scanBarcodes(in image: <span class="type">UIImage</span>) <span class="kw">async</span> -> [<span class="type">String</span>] {
        <span class="kw">guard</span> <span class="kw">let</span> cgImage = image.cgImage <span class="kw">else</span> { <span class="kw">return</span> [] }

        <span class="kw">let</span> request = <span class="type">VNDetectBarcodesRequest</span> { [<span class="kw">weak self</span>] request, _ <span class="kw">in</span>
            <span class="kw">guard</span> <span class="kw">let</span> results = request.results <span class="kw">as</span>? [<span class="type">VNBarcodeObservation</span>] <span class="kw">else</span> { <span class="kw">return</span> }
            <span class="kw">self</span>?.detectedCodes = results
        }

        <span class="comment">// íŠ¹ì • ë°”ì½”ë“œ íƒ€ì…ë§Œ ìŠ¤ìº” (QR, EAN-13 ë“±)</span>
        request.symbologies = [.qr, .ean13, .code128]

        <span class="kw">let</span> handler = <span class="type">VNImageRequestHandler</span>(cgImage: cgImage)
        <span class="kw">try</span>? handler.perform([request])

        <span class="kw">return</span> detectedCodes.compactMap { $0.payloadStringValue }
    }

    <span class="comment">// ì‹¤ì‹œê°„ ì¹´ë©”ë¼ ìŠ¤ìº”ìš©</span>
    <span class="kw">func</span> processCameraFrame(<span class="kw">_</span> sampleBuffer: <span class="type">CMSampleBuffer</span>) {
        <span class="kw">guard</span> <span class="kw">let</span> pixelBuffer = <span class="type">CMSampleBufferGetImageBuffer</span>(sampleBuffer) <span class="kw">else</span> { <span class="kw">return</span> }

        <span class="kw">let</span> request = <span class="type">VNDetectBarcodesRequest</span> { [<span class="kw">weak self</span>] request, _ <span class="kw">in</span>
            <span class="kw">guard</span> <span class="kw">let</span> results = request.results <span class="kw">as</span>? [<span class="type">VNBarcodeObservation</span>] <span class="kw">else</span> { <span class="kw">return</span> }
            <span class="kw">self</span>?.detectedCodes = results
        }

        <span class="kw">let</span> handler = <span class="type">VNImageRequestHandler</span>(cvPixelBuffer: pixelBuffer, options: [:])
        <span class="kw">try</span>? handler.perform([request])
    }
}</pre>
</div>

<h2>ğŸ¯ 4. ê°ì²´ ì¶”ì  (Object Tracking)</h2>
<p>ë¹„ë””ì˜¤ì—ì„œ íŠ¹ì • ê°ì²´ë¥¼ í”„ë ˆì„ ê°„ ì¶”ì .</p>

<div class="code-block">
<div class="code-header">ObjectTracker.swift â€” ê°ì²´ ì¶”ì </div>
<pre class="code-body"><span class="kw">import</span> <span class="type">Vision</span>

<span class="kw">@Observable</span>
<span class="kw">class</span> <span class="type">ObjectTracker</span> {
    <span class="kw">private</span> <span class="kw">var</span> trackingRequest: <span class="type">VNTrackObjectRequest</span>?
    <span class="kw">var</span> trackedObject: <span class="type">VNDetectedObjectObservation</span>?

    <span class="comment">// ì´ˆê¸° ê°ì²´ ìœ„ì¹˜ë¡œ ì¶”ì  ì‹œì‘</span>
    <span class="kw">func</span> startTracking(initialObservation: <span class="type">VNDetectedObjectObservation</span>) {
        trackingRequest = <span class="type">VNTrackObjectRequest</span>(detectedObjectObservation: initialObservation)
        trackingRequest?.trackingLevel = .accurate
    }

    <span class="comment">// ë‹¤ìŒ í”„ë ˆì„ ì²˜ë¦¬</span>
    <span class="kw">func</span> processFrame(<span class="kw">_</span> pixelBuffer: <span class="type">CVPixelBuffer</span>) -> <span class="type">CGRect</span>? {
        <span class="kw">guard</span> <span class="kw">let</span> request = trackingRequest <span class="kw">else</span> { <span class="kw">return</span> <span class="kw">nil</span> }

        <span class="kw">let</span> handler = <span class="type">VNSequenceRequestHandler</span>()
        <span class="kw">try</span>? handler.perform([request], on: pixelBuffer)

        <span class="kw">guard</span> <span class="kw">let</span> observation = request.results?.first <span class="kw">as</span>? <span class="type">VNDetectedObjectObservation</span> <span class="kw">else</span> {
            <span class="kw">return</span> <span class="kw">nil</span>
        }

        <span class="comment">// ì‹ ë¢°ë„ ì²´í¬</span>
        <span class="kw">if</span> observation.confidence > <span class="str">0.5</span> {
            trackedObject = observation
            <span class="kw">return</span> observation.boundingBox
        }

        <span class="kw">return</span> <span class="kw">nil</span>
    }

    <span class="kw">func</span> stopTracking() {
        trackingRequest = <span class="kw">nil</span>
        trackedObject = <span class="kw">nil</span>
    }
}</pre>
</div>

<h2>ğŸ” 5. ì´ë¯¸ì§€ ë¶„ì„ (Image Analysis)</h2>
<p>Analyze image properties (brightness, focus, horizon, etc.).</p>

<div class="code-block">
<div class="code-header">ImageAnalyzer.swift â€” ì´ë¯¸ì§€ ë¶„ì„</div>
<pre class="code-body"><span class="kw">import</span> <span class="type">Vision</span>

<span class="kw">struct</span> <span class="type">ImageAnalysisResult</span> {
    <span class="kw">let</span> brightness: <span class="type">Float</span>
    <span class="kw">let</span> contrast: <span class="type">Float</span>
    <span class="kw">let</span> horizonAngle: <span class="type">CGFloat</span>?
    <span class="kw">let</span> isFocused: <span class="type">Bool</span>
}

<span class="kw">@Observable</span>
<span class="kw">class</span> <span class="type">ImageAnalyzer</span> {
    <span class="kw">func</span> analyzeImage(<span class="kw">_</span> image: <span class="type">UIImage</span>) <span class="kw">async</span> -> <span class="type">ImageAnalysisResult</span>? {
        <span class="kw">guard</span> <span class="kw">let</span> cgImage = image.cgImage <span class="kw">else</span> { <span class="kw">return</span> <span class="kw">nil</span> }

        <span class="comment">// ì´ë¯¸ì§€ ì†ì„± ë¶„ì„</span>
        <span class="kw">let</span> featureRequest = <span class="type">VNDetectHorizonRequest</span>()
        <span class="kw">let</span> qualityRequest = <span class="type">VNClassifyImageRequest</span>()

        <span class="kw">let</span> handler = <span class="type">VNImageRequestHandler</span>(cgImage: cgImage)
        <span class="kw">try</span>? handler.perform([featureRequest, qualityRequest])

        <span class="kw">let</span> horizonAngle = (featureRequest.results?.first)?.angle

        <span class="kw">return</span> <span class="type">ImageAnalysisResult</span>(
            brightness: <span class="str">0.7</span>,
            contrast: <span class="str">0.8</span>,
            horizonAngle: horizonAngle,
            isFocused: <span class="kw">true</span>
        )
    }

    <span class="comment">// ìœ¤ê³½ì„  ê²€ì¶œ</span>
    <span class="kw">func</span> detectContours(in image: <span class="type">UIImage</span>) <span class="kw">async</span> -> [<span class="type">VNContoursObservation</span>]? {
        <span class="kw">guard</span> <span class="kw">let</span> cgImage = image.cgImage <span class="kw">else</span> { <span class="kw">return</span> <span class="kw">nil</span> }

        <span class="kw">let</span> request = <span class="type">VNDetectContoursRequest</span>()
        request.contrastAdjustment = <span class="str">2.0</span>
        request.detectsDarkOnLight = <span class="kw">true</span>

        <span class="kw">let</span> handler = <span class="type">VNImageRequestHandler</span>(cgImage: cgImage)
        <span class="kw">try</span>? handler.perform([request])

        <span class="kw">return</span> request.results
    }
}</pre>
</div>

<h2>ğŸ¤– 6. Core ML í†µí•©</h2>
<p>Combine Vision and Core ML to run custom models.</p>

<div class="code-block">
<div class="code-header">VisionMLIntegration.swift â€” Core ML Integration</div>
<pre class="code-body"><span class="kw">import</span> <span class="type">Vision</span>
<span class="kw">import</span> <span class="type">CoreML</span>

<span class="kw">@Observable</span>
<span class="kw">class</span> <span class="type">VisionMLClassifier</span> {
    <span class="kw">var</span> classification: <span class="type">String</span> = <span class="str">""</span>
    <span class="kw">var</span> confidence: <span class="type">Float</span> = <span class="str">0.0</span>

    <span class="kw">func</span> classify(image: <span class="type">UIImage</span>, model: <span class="type">MLModel</span>) <span class="kw">async</span> {
        <span class="kw">guard</span> <span class="kw">let</span> cgImage = image.cgImage <span class="kw">else</span> { <span class="kw">return</span> }

        <span class="comment">// Core ML ëª¨ë¸ì„ Vision ìš”ì²­ìœ¼ë¡œ ë˜í•‘</span>
        <span class="kw">guard</span> <span class="kw">let</span> visionModel = <span class="kw">try</span>? <span class="type">VNCoreMLModel</span>(for: model) <span class="kw">else</span> { <span class="kw">return</span> }

        <span class="kw">let</span> request = <span class="type">VNCoreMLRequest</span>(model: visionModel) { [<span class="kw">weak self</span>] request, error <span class="kw">in</span>
            <span class="kw">guard</span> <span class="kw">let</span> results = request.results <span class="kw">as</span>? [<span class="type">VNClassificationObservation</span>],
                  <span class="kw">let</span> topResult = results.first <span class="kw">else</span> { <span class="kw">return</span> }

            <span class="kw">self</span>?.classification = topResult.identifier
            <span class="kw">self</span>?.confidence = topResult.confidence
        }

        <span class="comment">// ì´ë¯¸ì§€ í¬ê¸° ìë™ ì¡°ì •</span>
        request.imageCropAndScaleOption = .centerCrop

        <span class="kw">let</span> handler = <span class="type">VNImageRequestHandler</span>(cgImage: cgImage)
        <span class="kw">try</span>? handler.perform([request])
    }
}</pre>
</div>

<h2>ğŸ“± SwiftUI Integration Example</h2>

<div class="code-block">
<div class="code-header">VisionDemoView.swift â€” Complete Demo</div>
<pre class="code-body"><span class="kw">import</span> <span class="type">SwiftUI</span>

<span class="kw">struct</span> <span class="type">VisionDemoView</span>: <span class="type">View</span> {
    <span class="kw">@State</span> <span class="kw">private</span> <span class="kw">var</span> selectedImage: <span class="type">UIImage</span>?
    <span class="kw">@State</span> <span class="kw">private</span> <span class="kw">var</span> faceDetector = <span class="type">FaceDetector</span>()
    <span class="kw">@State</span> <span class="kw">private</span> <span class="kw">var</span> textRecognizer = <span class="type">TextRecognizer</span>()
    <span class="kw">@State</span> <span class="kw">private</span> <span class="kw">var</span> barcodeScanner = <span class="type">BarcodeScanner</span>()
    <span class="kw">@State</span> <span class="kw">private</span> <span class="kw">var</span> selectedMode: <span class="type">Mode</span> = .face

    <span class="kw">enum</span> <span class="type">Mode</span>: <span class="type">String</span>, <span class="type">CaseIterable</span> {
        <span class="kw">case</span> face = <span class="str">"ì–¼êµ´ ì¸ì‹"</span>
        <span class="kw">case</span> text = <span class="str">"í…ìŠ¤íŠ¸ ì¸ì‹"</span>
        <span class="kw">case</span> barcode = <span class="str">"ë°”ì½”ë“œ ìŠ¤ìº”"</span>
    }

    <span class="kw">var</span> body: <span class="kw">some</span> <span class="type">View</span> {
        <span class="type">NavigationStack</span> {
            <span class="type">VStack</span>(spacing: <span class="str">20</span>) {
                <span class="comment">// ëª¨ë“œ ì„ íƒ</span>
                <span class="type">Picker</span>(<span class="str">"ëª¨ë“œ"</span>, selection: $selectedMode) {
                    <span class="type">ForEach</span>(<span class="type">Mode</span>.allCases, id: \.<span class="kw">self</span>) { mode <span class="kw">in</span>
                        <span class="type">Text</span>(mode.rawValue).tag(mode)
                    }
                }
                .pickerStyle(.segmented)
                .padding()

                <span class="comment">// ì´ë¯¸ì§€ í‘œì‹œ</span>
                <span class="kw">if</span> <span class="kw">let</span> image = selectedImage {
                    <span class="type">Image</span>(uiImage: image)
                        .resizable()
                        .scaledToFit()
                        .frame(maxHeight: <span class="str">300</span>)
                }

                <span class="comment">// ê²°ê³¼ í‘œì‹œ</span>
                resultView

                <span class="type">Spacer</span>()

                <span class="type">Button</span>(<span class="str">"ì‚¬ì§„ ì„ íƒí•˜ê³  ë¶„ì„"</span>) {
                    <span class="comment">// ì‚¬ì§„ ì„ íƒ ë¡œì§</span>
                }
                .buttonStyle(.borderedProminent)
            }
            .navigationTitle(<span class="str">"Vision ë°ëª¨"</span>)
        }
    }

    <span class="kw">@ViewBuilder</span>
    <span class="kw">var</span> resultView: <span class="kw">some</span> <span class="type">View</span> {
        <span class="kw">switch</span> selectedMode {
        <span class="kw">case</span> .face:
            <span class="type">Text</span>(<span class="str">"ê²€ì¶œëœ ì–¼êµ´: \(faceDetector.detectedFaces.count)ê°œ"</span>)
        <span class="kw">case</span> .text:
            <span class="type">ScrollView</span> {
                <span class="type">Text</span>(textRecognizer.recognizedText)
                    .padding()
            }
        <span class="kw">case</span> .barcode:
            <span class="type">VStack</span> {
                <span class="type">ForEach</span>(barcodeScanner.detectedCodes, id: \.<span class="kw">self</span>.uuid) { code <span class="kw">in</span>
                    <span class="type">Text</span>(code.payloadStringValue ?? <span class="str">"ì•Œ ìˆ˜ ì—†ìŒ"</span>)
                }
            }
        }
    }
}</pre>
</div>

<h2>ğŸ’¡ HIG Guidelines</h2>

<ul>
<li><strong>Permission Request:</strong> ì¹´ë©”ë¼ ì‚¬ìš© ì‹œ In Info.plist, <code>NSCameraUsageDescription</code> ì¶”ê°€</li>
<li><strong>ì„±ëŠ¥:</strong> ë°±ê·¸ë¼ìš´ë“œ íì—ì„œ Vision ìš”ì²­ ì²˜ë¦¬</li>
<li><strong>í”¼ë“œë°±:</strong> ì²˜ë¦¬ ì¤‘ì„ì„ ì‚¬ìš©ìì—ê²Œ ëª…í™•íˆ í‘œì‹œ</li>
<li><strong>ì •í™•ë„:</strong> Prevent false detections with confidence threshold settings</li>
<li><strong>Privacy:</strong> ì–¼êµ´ ì¸ì‹ ë°ì´í„°ëŠ” ê¸°ê¸°ì—ë§Œ ì €ì¥</li>
</ul>

<h2>ğŸ¯ Practical Usage</h2>

<ul>
<li><strong>ë¬¸ì„œ ìŠ¤ìºë„ˆ:</strong> OCRë¡œ ì˜ìˆ˜ì¦, ëª…í•¨, ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ</li>
<li><strong>AR Filters:</strong> ì–¼êµ´ ëœë“œë§ˆí¬ë¡œ ì‹¤ì‹œê°„ AR ì´í™íŠ¸</li>
<li><strong>QR ì²´í¬ì¸:</strong> ì´ë²¤íŠ¸ ì…ì¥ê¶Œ ìë™ ìŠ¤ìº”</li>
<li><strong>ìƒí’ˆ ì¸ì‹:</strong> ë°”ì½”ë“œ ìŠ¤ìº”ìœ¼ë¡œ ê°€ê²© ë¹„êµ</li>
<li><strong>ë¹„ë””ì˜¤ ë¶„ì„:</strong> ì˜ìƒ ì† ê°ì²´ ì¶”ì  ë° ë¶„ë¥˜</li>
</ul>

<h2>ğŸ“š Learn More</h2>

<ul>
<li><a href="https://developer.apple.com/documentation/vision">Vision Framework ê³µì‹ ë¬¸ì„œ</a></li>
<li><a href="https://developer.apple.com/videos/play/wwdc2023/10176/">WWDC: Explore 3D body pose and person segmentation</a></li>
<li><a href="https://developer.apple.com/documentation/vision/recognizing_text_in_images">Recognizing Text in Images</a></li>
<li><a href="https://developer.apple.com/documentation/vision/tracking_multiple_objects_or_rectangles_in_video">Tracking Objects in Video</a></li>
</ul>

<div class="info-box">
<strong>âš¡ï¸ Performance Tips:</strong> Using VNSequenceRequestHandler improves performance for continuous frame processing. Use .fast accuracy for real-time camera processing.
</div>

</article>
</body></html>