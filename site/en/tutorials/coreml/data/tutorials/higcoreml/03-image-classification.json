{"kind":"project","variants":[{"paths":["\/tutorials\/higcoreml\/03-image-classification"],"traits":[{"interfaceLanguage":"swift"}]}],"hierarchy":{"reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/Table-of-Contents","paths":[["doc:\/\/coreml.HIGCoreML\/tutorials\/Table-of-Contents","doc:\/\/coreml.HIGCoreML\/tutorials\/Table-of-Contents\/$volume","doc:\/\/coreml.HIGCoreML\/tutorials\/Table-of-Contents\/Part-2:-Image-Classification"]],"modules":[{"reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/Table-of-Contents\/Part-1:-Core-ML-Basics","projects":[{"reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/01-CoreML-Introduction","sections":[{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/01-CoreML-Introduction#What-is-Core-ML"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/01-CoreML-Introduction#Project-Setup"},{"kind":"assessment","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/01-CoreML-Introduction#Check-Your-Understanding"}]},{"reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/02-Loading-MLModel","sections":[{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/02-Loading-MLModel#Adding-an-MLModel"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/02-Loading-MLModel#Model-Loading-Patterns"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/02-Loading-MLModel#ImageClassifier-Service"},{"kind":"assessment","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/02-Loading-MLModel#Check-Your-Understanding"}]}]},{"reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/Table-of-Contents\/Part-2:-Image-Classification","projects":[{"reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/03-Image-Classification","sections":[{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/03-Image-Classification#Vision-+-Core-ML-Integration"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/03-Image-Classification#Parsing-Results"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/03-Image-Classification#UI-Integration"},{"kind":"assessment","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/03-Image-Classification#Check-Your-Understanding"}]},{"reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/04-Create-ML-Custom-Model","sections":[{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/04-Create-ML-Custom-Model#Introduction-to-Create-ML"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/04-Create-ML-Custom-Model#Preparing-Training-Data"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/04-Create-ML-Custom-Model#Training-the-Model"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/04-Create-ML-Custom-Model#Programmatic-Training"},{"kind":"assessment","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/04-Create-ML-Custom-Model#Check-Your-Understanding"}]}]},{"reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/Table-of-Contents\/Part-3:-Text-&-Sound","projects":[{"reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/05-Text-Classification","sections":[{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/05-Text-Classification#NLModel-Basics"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/05-Text-Classification#Building-a-Sentiment-Analysis-App"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/05-Text-Classification#Training-Text-Classifier-with-Create-ML"},{"kind":"assessment","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/05-Text-Classification#Check-Your-Understanding"}]},{"reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/06-Sound-Classification","sections":[{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/06-Sound-Classification#Sound-Analysis-Framework"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/06-Sound-Classification#Real-time-Audio-Analysis"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/06-Sound-Classification#Custom-Sound-Classifier"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/06-Sound-Classification#Sound-Classification-UI"},{"kind":"assessment","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/06-Sound-Classification#Check-Your-Understanding"}]}]},{"reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/Table-of-Contents\/Part-4:-Advanced-Features","projects":[{"reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/07-On-Device-Training","sections":[{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/07-On-Device-Training#Understanding-On-Device-Training"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/07-On-Device-Training#Creating-Updatable-Models"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/07-On-Device-Training#Implementing-MLUpdateTask"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/07-On-Device-Training#Practical-Example-Personalized-Classifier"},{"kind":"assessment","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/07-On-Device-Training#Check-Your-Understanding"}]},{"reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/08-Model-Optimization","sections":[{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/08-Model-Optimization#Why-Optimization-is-Needed"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/08-Model-Optimization#Quantization"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/08-Model-Optimization#Palettization"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/08-Model-Optimization#Neural-Engine-Optimization"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/08-Model-Optimization#Performance-Measurement"},{"kind":"assessment","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/08-Model-Optimization#Check-Your-Understanding"}]}]},{"reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/Table-of-Contents\/Part-5:-Integration-&-Deployment","projects":[{"reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/09-CoreML-Vision-Integration","sections":[{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/09-CoreML-Vision-Integration#Vision-High-Level-APIs"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/09-CoreML-Vision-Integration#Object-Detection"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/09-CoreML-Vision-Integration#Image-Segmentation"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/09-CoreML-Vision-Integration#Real-time-Camera-Analysis"},{"kind":"assessment","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/09-CoreML-Vision-Integration#Check-Your-Understanding"}]},{"reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/10-Model-Deployment","sections":[{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/10-Model-Deployment#Model-Deployment-Strategies"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/10-Model-Deployment#Model-Version-Management"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/10-Model-Deployment#Compiled-Model-Management"},{"kind":"task","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/10-Model-Deployment#App-Store-Submission-Considerations"},{"kind":"assessment","reference":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/10-Model-Deployment#Check-Your-Understanding"}]}]}]},"identifier":{"url":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/03-Image-Classification","interfaceLanguage":"swift"},"schemaVersion":{"minor":3,"major":0,"patch":0},"sections":[{"title":"Image Classification (VNCoreMLRequest)","chapter":"Part 2: Image Classification","estimatedTimeInMinutes":20,"kind":"hero","content":[{"inlineContent":[{"text":"Integrate the Vision framework with Core ML","type":"text"},{"text":" ","type":"text"},{"text":"to implement real-time image classification.","type":"text"}],"type":"paragraph"}]},{"kind":"tasks","tasks":[{"title":"Vision + Core ML Integration","contentSection":[{"content":[{"type":"paragraph","inlineContent":[{"text":"While you can use Core ML models directly,","type":"text"},{"text":" ","type":"text"},{"text":"using them with the ","type":"text"},{"inlineContent":[{"text":"Vision framework","type":"text"}],"type":"strong"},{"text":" ","type":"text"},{"text":"automates image preprocessing.","type":"text"}]},{"type":"paragraph","inlineContent":[{"text":"Vision handles resizing, cropping, and normalization automatically.","type":"text"}]}],"kind":"contentAndMedia","mediaPosition":"trailing"}],"anchor":"Vision-+-Core-ML-Integration","stepsSection":[{"type":"step","code":"03-vision-model.swift","media":null,"content":[{"inlineContent":[{"type":"strong","inlineContent":[{"text":"Creating VNCoreMLModel","type":"text"}]}],"type":"paragraph"}],"caption":[{"inlineContent":[{"text":"Wrap the Core ML model for use with Vision.","type":"text"}],"type":"paragraph"}],"runtimePreview":null},{"runtimePreview":null,"content":[{"type":"paragraph","inlineContent":[{"inlineContent":[{"text":"Creating VNCoreMLRequest","type":"text"}],"type":"strong"}]}],"media":null,"caption":[{"inlineContent":[{"text":"Create a classification request and define the result handler.","type":"text"}],"type":"paragraph"}],"type":"step","code":"03-classification-request.swift"},{"type":"step","code":"03-request-handler.swift","media":null,"content":[{"type":"paragraph","inlineContent":[{"inlineContent":[{"type":"text","text":"Executing with VNImageRequestHandler"}],"type":"strong"}]}],"caption":[{"inlineContent":[{"text":"Execute the classification request on an image.","type":"text"},{"text":" ","type":"text"},{"text":"Supports CGImage, CIImage, URL, and Data.","type":"text"}],"type":"paragraph"}],"runtimePreview":null}]},{"title":"Parsing Results","contentSection":[{"content":[{"inlineContent":[{"text":"Extract the highest probability classification results","type":"text"},{"type":"text","text":" "},{"text":"from the VNClassificationObservation array.","type":"text"}],"type":"paragraph"}],"mediaPosition":"trailing","kind":"contentAndMedia"}],"anchor":"Parsing-Results","stepsSection":[{"type":"step","code":"03-result-model.swift","media":null,"content":[{"inlineContent":[{"type":"strong","inlineContent":[{"type":"text","text":"Defining the Result Model"}]}],"type":"paragraph"}],"caption":[{"inlineContent":[{"type":"text","text":"Define a struct to hold classification results."},{"text":" ","type":"text"},{"text":"Include label, confidence, and top N results.","type":"text"}],"type":"paragraph"}],"runtimePreview":null},{"caption":[{"type":"paragraph","inlineContent":[{"type":"text","text":"Sort VNClassificationObservation by confidence"},{"type":"text","text":" "},{"type":"text","text":"and extract the top results."}]}],"content":[{"type":"paragraph","inlineContent":[{"type":"strong","inlineContent":[{"text":"Result Parsing Logic","type":"text"}]}]}],"media":null,"code":"03-result-parsing.swift","type":"step","runtimePreview":null},{"code":"03-confidence-threshold.swift","content":[{"inlineContent":[{"inlineContent":[{"type":"text","text":"Setting Confidence Threshold"}],"type":"strong"}],"type":"paragraph"}],"type":"step","caption":[{"inlineContent":[{"type":"text","text":"Treat results with too low confidence as “Unknown”."},{"type":"text","text":" "},{"text":"Generally, 50% or higher is considered a valid result.","type":"text"}],"type":"paragraph"}],"runtimePreview":null,"media":null}]},{"title":"UI Integration","contentSection":[{"content":[{"type":"paragraph","inlineContent":[{"text":"Complete a screen in SwiftUI that selects images","type":"text"},{"text":" ","type":"text"},{"text":"and displays classification results.","type":"text"}]}],"mediaPosition":"trailing","kind":"contentAndMedia"}],"anchor":"UI-Integration","stepsSection":[{"content":[{"type":"paragraph","inlineContent":[{"inlineContent":[{"text":"Selecting Images with PhotosPicker","type":"text"}],"type":"strong"}]}],"caption":[{"inlineContent":[{"text":"Use iOS 16+’s PhotosPicker to","type":"text"},{"text":" ","type":"text"},{"text":"select images from the photo library.","type":"text"}],"type":"paragraph"}],"code":"03-image-picker.swift","media":null,"type":"step","runtimePreview":null},{"content":[{"inlineContent":[{"inlineContent":[{"text":"Classification Results UI","type":"text"}],"type":"strong"}],"type":"paragraph"}],"caption":[{"inlineContent":[{"text":"Display the top 5 classification results with probability bars.","type":"text"}],"type":"paragraph"}],"code":"03-result-view.swift","media":null,"type":"step","runtimePreview":null},{"content":[{"inlineContent":[{"inlineContent":[{"text":"Complete Screen Integration","type":"text"}],"type":"strong"}],"type":"paragraph"}],"caption":[{"inlineContent":[{"type":"text","text":"Complete the entire flow from image selection"},{"type":"text","text":" "},{"type":"text","text":"to classification and result display."}],"type":"paragraph"}],"code":"03-classifier-screen.swift","media":null,"type":"step","runtimePreview":null}]}]},{"anchor":"Check-Your-Understanding","kind":"assessments","assessments":[{"title":[{"type":"paragraph","inlineContent":[{"text":"What is the biggest benefit of using the Vision framework with Core ML?","type":"text"}]}],"choices":[{"justification":[{"type":"paragraph","inlineContent":[{"text":"Vision automatically converts images to the format","type":"text"},{"text":" ","type":"text"},{"type":"text","text":"required by the model. No manual preprocessing needed."}]}],"isCorrect":true,"content":[{"type":"paragraph","inlineContent":[{"text":"Image preprocessing (resizing, normalization) is handled automatically","type":"text"}]}]},{"justification":[{"type":"paragraph","inlineContent":[{"text":"Speed is similar. Vision’s advantage is","type":"text"},{"text":" ","type":"text"},{"text":"automatic preprocessing and convenient APIs.","type":"text"}]}],"isCorrect":false,"content":[{"type":"paragraph","inlineContent":[{"text":"Faster inference speed","type":"text"}]}]},{"justification":[{"type":"paragraph","inlineContent":[{"text":"Accuracy is determined by the model.","type":"text"},{"text":" ","type":"text"},{"text":"Vision’s advantage is preprocessing automation.","type":"text"}]}],"isCorrect":false,"content":[{"type":"paragraph","inlineContent":[{"text":"More accurate results","type":"text"}]}]}],"content":[],"type":"multiple-choice"},{"title":[{"type":"paragraph","inlineContent":[{"type":"text","text":"What should you check first when parsing results from VNClassificationObservation?"}]}],"choices":[{"justification":[{"type":"paragraph","inlineContent":[{"text":"Results with low confidence cannot be trusted.","type":"text"},{"text":" ","type":"text"},{"text":"Typically, 50% is used as the threshold.","type":"text"}]}],"isCorrect":true,"content":[{"type":"paragraph","inlineContent":[{"text":"The confidence value","type":"text"}]}]},{"justification":[{"type":"paragraph","inlineContent":[{"text":"Label length is not important.","type":"text"},{"text":" ","type":"text"},{"text":"Confidence is the most important metric.","type":"text"}]}],"isCorrect":false,"content":[{"type":"paragraph","inlineContent":[{"text":"The label string length","type":"text"}]}]},{"justification":[{"type":"paragraph","inlineContent":[{"text":"The confidence of each result is more important","type":"text"},{"text":" ","type":"text"},{"text":"than the number of results.","type":"text"}]}],"isCorrect":false,"content":[{"type":"paragraph","inlineContent":[{"text":"The size of the result array","type":"text"}]}]}],"content":[],"type":"multiple-choice"}]},{"action":{"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/04-Create-ML-Custom-Model","overridingTitle":"Get started","isActive":true,"overridingTitleInlineContent":[{"type":"text","text":"Get started"}],"type":"reference"},"title":"Creating Custom Models with Create ML","featuredEyebrow":"Tutorial","kind":"callToAction","abstract":[{"text":"Use Apple’s Create ML app to","type":"text"},{"text":" ","type":"text"},{"text":"train your own image classification model.","type":"text"}]}],"metadata":{"title":"Image Classification (VNCoreMLRequest)","categoryPathComponent":"Table-of-Contents","category":"Core ML Image Classification App Challenge","role":"project"},"references":{"doc://coreml.HIGCoreML/tutorials/HIGCoreML/10-Model-Deployment#Model-Deployment-Strategies":{"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/10-Model-Deployment#Model-Deployment-Strategies","abstract":[{"type":"text","text":"Learn strategies and best practices for managing"},{"type":"text","text":" "},{"type":"text","text":"ML models when deploying to the App Store."}],"url":"\/tutorials\/higcoreml\/10-model-deployment#Model-Deployment-Strategies","type":"section","kind":"section","title":"Model Deployment Strategies","role":"pseudoSymbol"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/06-Sound-Classification":{"type":"topic","title":"Sound Classification","kind":"project","abstract":[{"text":"Build an app that analyzes microphone input in real-time","type":"text"},{"text":" ","type":"text"},{"text":"to recognize different types of sounds.","type":"text"}],"url":"\/tutorials\/higcoreml\/06-sound-classification","role":"project","estimatedTime":"20min","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/06-Sound-Classification"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/04-Create-ML-Custom-Model#Programmatic-Training":{"type":"section","title":"Programmatic Training","abstract":[{"type":"text","text":"Use Apple’s Create ML app to"},{"type":"text","text":" "},{"type":"text","text":"train your own image classification model."}],"kind":"section","url":"\/tutorials\/higcoreml\/04-create-ml-custom-model#Programmatic-Training","role":"pseudoSymbol","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/04-Create-ML-Custom-Model#Programmatic-Training"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/03-Image-Classification#Check-Your-Understanding":{"titleInlineContent":[{"text":"Check Your Understanding","type":"text"}],"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/03-Image-Classification#Check-Your-Understanding","url":"\/tutorials\/higcoreml\/03-image-classification#Check-Your-Understanding","title":"Check Your Understanding","type":"link"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/09-CoreML-Vision-Integration":{"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/09-CoreML-Vision-Integration","abstract":[{"type":"text","text":"Combine Vision’s high-level APIs with Core ML to implement"},{"type":"text","text":" "},{"type":"text","text":"complex vision tasks like object detection and segmentation."}],"kind":"project","url":"\/tutorials\/higcoreml\/09-coreml-vision-integration","type":"topic","estimatedTime":"15min","title":"Core ML + Vision Integration","role":"project"},"doc://coreml.HIGCoreML/tutorials/Table-of-Contents/Part-1:-Core-ML-Basics":{"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/Table-of-Contents\/Part-1:-Core-ML-Basics","abstract":[],"url":"\/tutorials\/table-of-contents\/part-1:-core-ml-basics","type":"topic","kind":"article","title":"Part 1: Core ML Basics","role":"article"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/06-Sound-Classification#Real-time-Audio-Analysis":{"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/06-Sound-Classification#Real-time-Audio-Analysis","abstract":[{"type":"text","text":"Build an app that analyzes microphone input in real-time"},{"type":"text","text":" "},{"type":"text","text":"to recognize different types of sounds."}],"url":"\/tutorials\/higcoreml\/06-sound-classification#Real-time-Audio-Analysis","type":"section","kind":"section","title":"Real-time Audio Analysis","role":"pseudoSymbol"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/04-Create-ML-Custom-Model#Preparing-Training-Data":{"type":"section","title":"Preparing Training Data","kind":"section","abstract":[{"text":"Use Apple’s Create ML app to","type":"text"},{"text":" ","type":"text"},{"text":"train your own image classification model.","type":"text"}],"url":"\/tutorials\/higcoreml\/04-create-ml-custom-model#Preparing-Training-Data","role":"pseudoSymbol","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/04-Create-ML-Custom-Model#Preparing-Training-Data"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/07-On-Device-Training#Practical-Example-Personalized-Classifier":{"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/07-On-Device-Training#Practical-Example-Personalized-Classifier","abstract":[{"text":"Implement personalized AI experiences by","type":"text"},{"text":" ","type":"text"},{"text":"updating models directly on the user’s device.","type":"text"}],"url":"\/tutorials\/higcoreml\/07-on-device-training#Practical-Example-Personalized-Classifier","type":"section","kind":"section","title":"Practical Example: Personalized Classifier","role":"pseudoSymbol"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/05-Text-Classification#Building-a-Sentiment-Analysis-App":{"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/05-Text-Classification#Building-a-Sentiment-Analysis-App","abstract":[{"type":"text","text":"Implement text classification such as sentiment analysis"},{"type":"text","text":" "},{"type":"text","text":"and spam filtering using Natural Language framework and Core ML."}],"url":"\/tutorials\/higcoreml\/05-text-classification#Building-a-Sentiment-Analysis-App","type":"section","kind":"section","title":"Building a Sentiment Analysis App","role":"pseudoSymbol"},"03-vision-model.swift":{"type":"file","highlights":[],"fileName":"VisionSetup.swift","identifier":"03-vision-model.swift","content":["import CoreML","import Vision","","\/\/\/ Vision에서 CoreML 모델 사용하기","\/\/\/","\/\/\/ VNCoreMLModel로 래핑하면 이미지 전처리가 자동 처리됩니다.","struct VisionModelSetup {","    ","    \/\/\/ VNCoreMLModel 생성","    func createVisionModel() throws -> VNCoreMLModel {","        \/\/ 1. CoreML 모델 로드","        let configuration = MLModelConfiguration()","        let coreMLModel = try MobileNetV2(configuration: configuration)","        ","        \/\/ 2. Vision용 모델로 래핑","        let visionModel = try VNCoreMLModel(for: coreMLModel.model)","        ","        return visionModel","    }","    ","    \/\/\/ Vision 사용의 장점","    \/\/\/","    \/\/\/ 1. 자동 이미지 리사이징","    \/\/\/    - 모델이 224×224를 요구하면 자동 변환","    \/\/\/","    \/\/\/ 2. 자동 색상 공간 변환","    \/\/\/    - sRGB, Display P3 등 자동 처리","    \/\/\/","    \/\/\/ 3. 자동 방향 보정","    \/\/\/    - EXIF orientation 자동 적용","    \/\/\/","    \/\/\/ 4. 배치 처리 지원","    \/\/\/    - 여러 이미지 동시 분석","}","","\/\/ Vision 없이 직접 CoreML 사용 시 필요한 전처리 (비교용)","extension VisionModelSetup {","    ","    \/\/\/ 직접 전처리 (Vision 없이) - 복잡함!","    func manualPreprocessing(image: UIImage) -> CVPixelBuffer? {","        \/\/ 1. 이미지 리사이징","        let targetSize = CGSize(width: 224, height: 224)","        UIGraphicsBeginImageContextWithOptions(targetSize, true, 1.0)","        image.draw(in: CGRect(origin: .zero, size: targetSize))","        let resizedImage = UIGraphicsGetImageFromCurrentImageContext()","        UIGraphicsEndImageContext()","        ","        guard let cgImage = resizedImage?.cgImage else { return nil }","        ","        \/\/ 2. CVPixelBuffer 생성","        var pixelBuffer: CVPixelBuffer?","        let attrs = [","            kCVPixelBufferCGImageCompatibilityKey: kCFBooleanTrue!,","            kCVPixelBufferCGBitmapContextCompatibilityKey: kCFBooleanTrue!","        ] as CFDictionary","        ","        CVPixelBufferCreate(","            kCFAllocatorDefault,","            224, 224,","            kCVPixelFormatType_32ARGB,","            attrs,","            &pixelBuffer","        )","        ","        guard let buffer = pixelBuffer else { return nil }","        ","        \/\/ 3. 이미지 그리기","        CVPixelBufferLockBaseAddress(buffer, [])","        let context = CGContext(","            data: CVPixelBufferGetBaseAddress(buffer),","            width: 224,","            height: 224,","            bitsPerComponent: 8,","            bytesPerRow: CVPixelBufferGetBytesPerRow(buffer),","            space: CGColorSpaceCreateDeviceRGB(),","            bitmapInfo: CGImageAlphaInfo.noneSkipFirst.rawValue","        )","        context?.draw(cgImage, in: CGRect(x: 0, y: 0, width: 224, height: 224))","        CVPixelBufferUnlockBaseAddress(buffer, [])","        ","        return buffer","    }","}","","import UIKit"],"fileType":"swift","syntax":"swift"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/09-CoreML-Vision-Integration#Check-Your-Understanding":{"url":"\/tutorials\/higcoreml\/09-coreml-vision-integration#Check-Your-Understanding","type":"link","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/09-CoreML-Vision-Integration#Check-Your-Understanding","title":"Check Your Understanding","titleInlineContent":[{"text":"Check Your Understanding","type":"text"}]},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/09-CoreML-Vision-Integration#Real-time-Camera-Analysis":{"type":"section","abstract":[{"type":"text","text":"Combine Vision’s high-level APIs with Core ML to implement"},{"text":" ","type":"text"},{"type":"text","text":"complex vision tasks like object detection and segmentation."}],"kind":"section","title":"Real-time Camera Analysis","url":"\/tutorials\/higcoreml\/09-coreml-vision-integration#Real-time-Camera-Analysis","role":"pseudoSymbol","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/09-CoreML-Vision-Integration#Real-time-Camera-Analysis"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/04-Create-ML-Custom-Model#Training-the-Model":{"type":"section","title":"Training the Model","abstract":[{"text":"Use Apple’s Create ML app to","type":"text"},{"text":" ","type":"text"},{"type":"text","text":"train your own image classification model."}],"kind":"section","url":"\/tutorials\/higcoreml\/04-create-ml-custom-model#Training-the-Model","role":"pseudoSymbol","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/04-Create-ML-Custom-Model#Training-the-Model"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/07-On-Device-Training#Check-Your-Understanding":{"url":"\/tutorials\/higcoreml\/07-on-device-training#Check-Your-Understanding","type":"link","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/07-On-Device-Training#Check-Your-Understanding","title":"Check Your Understanding","titleInlineContent":[{"text":"Check Your Understanding","type":"text"}]},"03-result-view.swift":{"type":"file","highlights":[],"fileName":"ResultView.swift","identifier":"03-result-view.swift","content":["import SwiftUI","","\/\/\/ 분류 결과 표시 뷰","struct ClassificationResultView: View {","    let result: ImageClassificationResult","    ","    var body: some View {","        VStack(alignment: .leading, spacing: 16) {","            \/\/ 최상위 결과","            topResultView","            ","            Divider()","            ","            \/\/ 상위 5개 결과 바","            resultsBarView","            ","            \/\/ 분류 시간","            if result.classificationTime > 0 {","                Text(\"분류 시간: \\(String(format: \"%.0fms\", result.classificationTime * 1000))\")","                    .font(.caption)","                    .foregroundStyle(.secondary)","            }","        }","        .padding()","        .background(Color.gray.opacity(0.05))","        .clipShape(RoundedRectangle(cornerRadius: 16))","    }","    ","    \/\/ MARK: - 최상위 결과","    @ViewBuilder","    private var topResultView: some View {","        HStack(alignment: .top) {","            VStack(alignment: .leading, spacing: 4) {","                Text(result.topLabel)","                    .font(.title2)","                    .fontWeight(.bold)","                    .lineLimit(2)","                ","                HStack(spacing: 4) {","                    Image(systemName: result.isValid ? \"checkmark.circle.fill\" : \"questionmark.circle.fill\")","                        .foregroundStyle(result.isValid ? .green : .orange)","                    ","                    Text(result.confidenceText)","                        .font(.headline)","                        .foregroundStyle(result.isValid ? .green : .orange)","                }","            }","            ","            Spacer()","            ","            \/\/ 신뢰도 게이지","            ZStack {","                Circle()","                    .stroke(Color.gray.opacity(0.2), lineWidth: 8)","                ","                Circle()","                    .trim(from: 0, to: CGFloat(result.topConfidence))","                    .stroke(","                        result.isValid ? Color.green : Color.orange,","                        style: StrokeStyle(lineWidth: 8, lineCap: .round)","                    )","                    .rotationEffect(.degrees(-90))","                ","                Text(result.confidenceText)","                    .font(.caption)","                    .fontWeight(.semibold)","            }","            .frame(width: 60, height: 60)","        }","    }","    ","    \/\/ MARK: - 상위 결과 바","    @ViewBuilder","    private var resultsBarView: some View {","        VStack(alignment: .leading, spacing: 8) {","            Text(\"상위 결과\")","                .font(.headline)","                .foregroundStyle(.secondary)","            ","            ForEach(result.topResults) { classification in","                HStack {","                    Text(classification.label)","                        .font(.subheadline)","                        .lineLimit(1)","                        .frame(maxWidth: 150, alignment: .leading)","                    ","                    GeometryReader { geometry in","                        ZStack(alignment: .leading) {","                            Rectangle()","                                .fill(Color.gray.opacity(0.2))","                                .frame(height: 8)","                                .clipShape(Capsule())","                            ","                            Rectangle()","                                .fill(barColor(for: classification.confidence))","                                .frame(","                                    width: geometry.size.width * classification.progress,","                                    height: 8","                                )","                                .clipShape(Capsule())","                        }","                    }","                    .frame(height: 8)","                    ","                    Text(classification.confidenceText)","                        .font(.caption)","                        .foregroundStyle(.secondary)","                        .frame(width: 50, alignment: .trailing)","                }","            }","        }","    }","    ","    private func barColor(for confidence: Float) -> Color {","        switch confidence {","        case 0.8...: return .green","        case 0.5..<0.8: return .blue","        case 0.2..<0.5: return .orange","        default: return .gray","        }","    }","}","","#Preview {","    ClassificationResultView(result: .preview)","        .padding()","}"],"fileType":"swift","syntax":"swift"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/05-Text-Classification":{"type":"topic","title":"Text Classification","kind":"project","abstract":[{"type":"text","text":"Implement text classification such as sentiment analysis"},{"text":" ","type":"text"},{"type":"text","text":"and spam filtering using Natural Language framework and Core ML."}],"url":"\/tutorials\/higcoreml\/05-text-classification","role":"project","estimatedTime":"18min","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/05-Text-Classification"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/02-Loading-MLModel#Model-Loading-Patterns":{"type":"section","title":"Model Loading Patterns","kind":"section","abstract":[{"type":"text","text":"Learn how to add .mlmodel files to your project"},{"text":" ","type":"text"},{"text":"and load and use models in Swift.","type":"text"}],"url":"\/tutorials\/higcoreml\/02-loading-mlmodel#Model-Loading-Patterns","role":"pseudoSymbol","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/02-Loading-MLModel#Model-Loading-Patterns"},"doc://coreml.HIGCoreML/tutorials/Table-of-Contents/Part-3:-Text-&-Sound":{"type":"topic","title":"Part 3: Text & Sound","abstract":[],"kind":"article","url":"\/tutorials\/table-of-contents\/part-3:-text-&-sound","role":"article","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/Table-of-Contents\/Part-3:-Text-&-Sound"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/05-Text-Classification#Training-Text-Classifier-with-Create-ML":{"type":"section","title":"Training Text Classifier with Create ML","abstract":[{"type":"text","text":"Implement text classification such as sentiment analysis"},{"type":"text","text":" "},{"type":"text","text":"and spam filtering using Natural Language framework and Core ML."}],"kind":"section","url":"\/tutorials\/higcoreml\/05-text-classification#Training-Text-Classifier-with-Create-ML","role":"pseudoSymbol","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/05-Text-Classification#Training-Text-Classifier-with-Create-ML"},"03-image-picker.swift":{"type":"file","highlights":[],"fileName":"ImagePicker.swift","identifier":"03-image-picker.swift","content":["import SwiftUI","import PhotosUI","","\/\/\/ iOS 16+ PhotosPicker 사용","struct ModernImagePicker: View {","    @Binding var selectedImage: UIImage?","    @State private var selectedItem: PhotosPickerItem?","    ","    var body: some View {","        PhotosPicker(","            selection: $selectedItem,","            matching: .images,","            photoLibrary: .shared()","        ) {","            Label(\"사진 선택\", systemImage: \"photo.fill\")","                .font(.headline)","                .padding()","                .frame(maxWidth: .infinity)","                .background(Color.blue)","                .foregroundStyle(.white)","                .clipShape(RoundedRectangle(cornerRadius: 12))","        }","        .onChange(of: selectedItem) { _, newValue in","            Task {","                await loadImage(from: newValue)","            }","        }","    }","    ","    private func loadImage(from item: PhotosPickerItem?) async {","        guard let item = item else { return }","        ","        \/\/ Data로 로드","        if let data = try? await item.loadTransferable(type: Data.self),","           let image = UIImage(data: data) {","            await MainActor.run {","                selectedImage = image","            }","        }","    }","}","","\/\/ MARK: - 카메라 + 사진첩 선택 버튼","struct ImageSourcePicker: View {","    @Binding var selectedImage: UIImage?","    @State private var showingImageSource = false","    @State private var showingCamera = false","    @State private var showingPhotoPicker = false","    @State private var photoPickerItem: PhotosPickerItem?","    ","    var body: some View {","        Menu {","            Button {","                showingCamera = true","            } label: {","                Label(\"카메라\", systemImage: \"camera.fill\")","            }","            ","            Button {","                showingPhotoPicker = true","            } label: {","                Label(\"사진첩\", systemImage: \"photo.on.rectangle\")","            }","        } label: {","            Label(\"이미지 선택\", systemImage: \"plus.circle.fill\")","                .font(.headline)","                .padding()","                .frame(maxWidth: .infinity)","                .background(Color.blue)","                .foregroundStyle(.white)","                .clipShape(RoundedRectangle(cornerRadius: 12))","        }","        .photosPicker(","            isPresented: $showingPhotoPicker,","            selection: $photoPickerItem,","            matching: .images","        )","        .fullScreenCover(isPresented: $showingCamera) {","            CameraView(capturedImage: $selectedImage)","        }","        .onChange(of: photoPickerItem) { _, newValue in","            Task {","                if let data = try? await newValue?.loadTransferable(type: Data.self),","                   let image = UIImage(data: data) {","                    selectedImage = image","                }","            }","        }","    }","}","","\/\/ MARK: - 카메라 뷰 (UIKit 래핑)","struct CameraView: UIViewControllerRepresentable {","    @Binding var capturedImage: UIImage?","    @Environment(\\.dismiss) private var dismiss","    ","    func makeUIViewController(context: Context) -> UIImagePickerController {","        let picker = UIImagePickerController()","        picker.sourceType = .camera","        picker.delegate = context.coordinator","        return picker","    }","    ","    func updateUIViewController(_ uiViewController: UIImagePickerController, context: Context) {}","    ","    func makeCoordinator() -> Coordinator {","        Coordinator(self)","    }","    ","    class Coordinator: NSObject, UIImagePickerControllerDelegate, UINavigationControllerDelegate {","        let parent: CameraView","        ","        init(_ parent: CameraView) {","            self.parent = parent","        }","        ","        func imagePickerController(","            _ picker: UIImagePickerController,","            didFinishPickingMediaWithInfo info: [UIImagePickerController.InfoKey: Any]","        ) {","            if let image = info[.originalImage] as? UIImage {","                parent.capturedImage = image","            }","            parent.dismiss()","        }","        ","        func imagePickerControllerDidCancel(_ picker: UIImagePickerController) {","            parent.dismiss()","        }","    }","}"],"fileType":"swift","syntax":"swift"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/02-Loading-MLModel#Check-Your-Understanding":{"url":"\/tutorials\/higcoreml\/02-loading-mlmodel#Check-Your-Understanding","type":"link","titleInlineContent":[{"type":"text","text":"Check Your Understanding"}],"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/02-Loading-MLModel#Check-Your-Understanding","title":"Check Your Understanding"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/10-Model-Deployment#Model-Version-Management":{"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/10-Model-Deployment#Model-Version-Management","abstract":[{"type":"text","text":"Learn strategies and best practices for managing"},{"type":"text","text":" "},{"type":"text","text":"ML models when deploying to the App Store."}],"url":"\/tutorials\/higcoreml\/10-model-deployment#Model-Version-Management","type":"section","kind":"section","title":"Model Version Management","role":"pseudoSymbol"},"03-classification-request.swift":{"type":"file","highlights":[],"fileName":"ClassificationRequest.swift","identifier":"03-classification-request.swift","content":["import Vision","import CoreML","","\/\/\/ VNCoreMLRequest로 분류 요청 생성","struct ClassificationRequestSetup {","    ","    \/\/\/ 기본 분류 요청 생성","    func createRequest(model: VNCoreMLModel) -> VNCoreMLRequest {","        let request = VNCoreMLRequest(model: model) { request, error in","            \/\/ 결과 처리 핸들러","            if let error = error {","                print(\"분류 에러: \\(error.localizedDescription)\")","                return","            }","            ","            guard let results = request.results as? [VNClassificationObservation] else {","                print(\"결과 타입 오류\")","                return","            }","            ","            \/\/ 상위 5개 결과 출력","            for result in results.prefix(5) {","                let confidence = result.confidence * 100","                print(\"\\(result.identifier): \\(String(format: \"%.2f\", confidence))%\")","            }","        }","        ","        \/\/ 이미지 크롭 옵션 설정","        request.imageCropAndScaleOption = .centerCrop","        ","        return request","    }","    ","    \/\/\/ 이미지 크롭 옵션들","    \/\/\/","    \/\/\/ - .centerCrop: 중앙 기준 정사각형 크롭 (권장)","    \/\/\/ - .scaleFit: 비율 유지하며 맞춤 (여백 발생)","    \/\/\/ - .scaleFill: 비율 유지하며 채움 (일부 잘림)","    func cropOptions() -> [VNImageCropAndScaleOption] {","        return [.centerCrop, .scaleFit, .scaleFill]","    }","}","","\/\/ MARK: - Async\/Await 패턴 (iOS 15+)","extension ClassificationRequestSetup {","    ","    \/\/\/ async\/await로 분류 요청 실행","    func classifyAsync(image: CGImage, model: VNCoreMLModel) async throws -> [VNClassificationObservation] {","        let request = VNCoreMLRequest(model: model)","        request.imageCropAndScaleOption = .centerCrop","        ","        let handler = VNImageRequestHandler(cgImage: image, options: [:])","        ","        \/\/ 백그라운드에서 실행","        return try await withCheckedThrowingContinuation { continuation in","            DispatchQueue.global(qos: .userInitiated).async {","                do {","                    try handler.perform([request])","                    ","                    guard let results = request.results as? [VNClassificationObservation] else {","                        continuation.resume(throwing: ClassificationError.invalidResults)","                        return","                    }","                    ","                    continuation.resume(returning: results)","                } catch {","                    continuation.resume(throwing: error)","                }","            }","        }","    }","}","","enum ClassificationError: Error {","    case invalidResults","    case modelNotReady","}"],"fileType":"swift","syntax":"swift"},"03-classifier-screen.swift":{"type":"file","highlights":[],"fileName":"ClassifierScreen.swift","identifier":"03-classifier-screen.swift","content":["import SwiftUI","import PhotosUI","import CoreML","import Vision","","\/\/\/ 이미지 분류 전체 화면","struct ImageClassifierScreen: View {","    @StateObject private var viewModel = ImageClassifierViewModel()","    ","    var body: some View {","        NavigationStack {","            ScrollView {","                VStack(spacing: 20) {","                    \/\/ 상태 표시","                    statusBadge","                    ","                    \/\/ 이미지 영역","                    imageArea","                    ","                    \/\/ 결과 영역","                    if let result = viewModel.result {","                        ClassificationResultView(result: result)","                    }","                    ","                    \/\/ 에러 메시지","                    if let error = viewModel.errorMessage {","                        errorView(message: error)","                    }","                }","                .padding()","            }","            .navigationTitle(\"이미지 분류\")","            .toolbar {","                ToolbarItem(placement: .primaryAction) {","                    imagePickerMenu","                }","            }","        }","    }","    ","    \/\/ MARK: - Status Badge","    @ViewBuilder","    private var statusBadge: some View {","        HStack(spacing: 8) {","            Circle()","                .fill(viewModel.isModelReady ? Color.green : Color.orange)","                .frame(width: 8, height: 8)","            ","            Text(viewModel.statusText)","                .font(.caption)","                .foregroundStyle(.secondary)","        }","        .padding(.horizontal, 12)","        .padding(.vertical, 6)","        .background(Color.gray.opacity(0.1))","        .clipShape(Capsule())","    }","    ","    \/\/ MARK: - Image Area","    @ViewBuilder","    private var imageArea: some View {","        ZStack {","            RoundedRectangle(cornerRadius: 20)","                .fill(Color.gray.opacity(0.08))","                .frame(height: 300)","            ","            if let image = viewModel.selectedImage {","                Image(uiImage: image)","                    .resizable()","                    .scaledToFit()","                    .clipShape(RoundedRectangle(cornerRadius: 16))","                    .padding()","            } else {","                VStack(spacing: 12) {","                    Image(systemName: \"photo.badge.plus\")","                        .font(.system(size: 50))","                        .foregroundStyle(.gray)","                    ","                    Text(\"분류할 이미지를 선택하세요\")","                        .foregroundStyle(.secondary)","                }","            }","            ","            if viewModel.isClassifying {","                Color.black.opacity(0.3)","                    .clipShape(RoundedRectangle(cornerRadius: 20))","                ","                ProgressView()","                    .scaleEffect(1.5)","                    .tint(.white)","            }","        }","    }","    ","    \/\/ MARK: - Image Picker Menu","    @ViewBuilder","    private var imagePickerMenu: some View {","        Menu {","            PhotosPicker(","                selection: $viewModel.selectedPhotoItem,","                matching: .images","            ) {","                Label(\"사진첩\", systemImage: \"photo.on.rectangle\")","            }","            ","            Button {","                viewModel.showCamera = true","            } label: {","                Label(\"카메라\", systemImage: \"camera\")","            }","        } label: {","            Image(systemName: \"plus.circle.fill\")","                .font(.title2)","        }","        .disabled(!viewModel.isModelReady)","        .fullScreenCover(isPresented: $viewModel.showCamera) {","            CameraView(capturedImage: $viewModel.cameraImage)","        }","    }","    ","    \/\/ MARK: - Error View","    private func errorView(message: String) -> some View {","        HStack {","            Image(systemName: \"exclamationmark.triangle.fill\")","                .foregroundStyle(.red)","            Text(message)","                .font(.caption)","        }","        .padding()","        .background(Color.red.opacity(0.1))","        .clipShape(RoundedRectangle(cornerRadius: 8))","    }","}","","\/\/ MARK: - ViewModel","@MainActor","class ImageClassifierViewModel: ObservableObject {","    @Published var selectedImage: UIImage?","    @Published var selectedPhotoItem: PhotosPickerItem? {","        didSet { loadSelectedPhoto() }","    }","    @Published var cameraImage: UIImage? {","        didSet { processImage(cameraImage) }","    }","    @Published var result: ImageClassificationResult?","    @Published var isClassifying = false","    @Published var isModelReady = false","    @Published var errorMessage: String?","    @Published var showCamera = false","    ","    private var visionModel: VNCoreMLModel?","    ","    var statusText: String {","        if isClassifying { return \"분류 중...\" }","        if isModelReady { return \"준비됨\" }","        return \"모델 로딩 중...\"","    }","    ","    init() {","        Task { await loadModel() }","    }","    ","    private func loadModel() async {","        do {","            let config = MLModelConfiguration()","            let model = try MobileNetV2(configuration: config)","            visionModel = try VNCoreMLModel(for: model.model)","            isModelReady = true","        } catch {","            errorMessage = \"모델 로딩 실패: \\(error.localizedDescription)\"","        }","    }","    ","    private func loadSelectedPhoto() {","        Task {","            guard let item = selectedPhotoItem,","                  let data = try? await item.loadTransferable(type: Data.self),","                  let image = UIImage(data: data) else { return }","            processImage(image)","        }","    }","    ","    private func processImage(_ image: UIImage?) {","        guard let image = image else { return }","        selectedImage = image","        classify(image: image)","    }","    ","    private func classify(image: UIImage) {","        guard let model = visionModel, let cgImage = image.cgImage else { return }","        ","        isClassifying = true","        errorMessage = nil","        ","        let startTime = CFAbsoluteTimeGetCurrent()","        ","        let request = VNCoreMLRequest(model: model) { [weak self] request, error in","            DispatchQueue.main.async {","                self?.isClassifying = false","                ","                if let error = error {","                    self?.errorMessage = error.localizedDescription","                    return","                }","                ","                guard let results = request.results as? [VNClassificationObservation] else {","                    self?.errorMessage = \"결과 파싱 실패\"","                    return","                }","                ","                let elapsed = CFAbsoluteTimeGetCurrent() - startTime","                self?.result = ImageClassificationResult(from: results, time: elapsed)","            }","        }","        request.imageCropAndScaleOption = .centerCrop","        ","        DispatchQueue.global(qos: .userInitiated).async {","            let handler = VNImageRequestHandler(cgImage: cgImage, options: [:])","            try? handler.perform([request])","        }","    }","}","","#Preview {","    ImageClassifierScreen()","}"],"fileType":"swift","syntax":"swift"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/05-Text-Classification#NLModel-Basics":{"type":"section","title":"NLModel Basics","kind":"section","abstract":[{"text":"Implement text classification such as sentiment analysis","type":"text"},{"type":"text","text":" "},{"type":"text","text":"and spam filtering using Natural Language framework and Core ML."}],"url":"\/tutorials\/higcoreml\/05-text-classification#NLModel-Basics","role":"pseudoSymbol","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/05-Text-Classification#NLModel-Basics"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/08-Model-Optimization#Neural-Engine-Optimization":{"type":"section","title":"Neural Engine Optimization","abstract":[{"type":"text","text":"Learn optimization techniques to reduce Core ML model size"},{"type":"text","text":" "},{"type":"text","text":"and improve inference speed."}],"kind":"section","url":"\/tutorials\/higcoreml\/08-model-optimization#Neural-Engine-Optimization","role":"pseudoSymbol","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/08-Model-Optimization#Neural-Engine-Optimization"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/10-Model-Deployment#Check-Your-Understanding":{"url":"\/tutorials\/higcoreml\/10-model-deployment#Check-Your-Understanding","type":"link","titleInlineContent":[{"type":"text","text":"Check Your Understanding"}],"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/10-Model-Deployment#Check-Your-Understanding","title":"Check Your Understanding"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/09-CoreML-Vision-Integration#Vision-High-Level-APIs":{"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/09-CoreML-Vision-Integration#Vision-High-Level-APIs","abstract":[{"type":"text","text":"Combine Vision’s high-level APIs with Core ML to implement"},{"type":"text","text":" "},{"type":"text","text":"complex vision tasks like object detection and segmentation."}],"url":"\/tutorials\/higcoreml\/09-coreml-vision-integration#Vision-High-Level-APIs","type":"section","kind":"section","title":"Vision High-Level APIs","role":"pseudoSymbol"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/09-CoreML-Vision-Integration#Object-Detection":{"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/09-CoreML-Vision-Integration#Object-Detection","abstract":[{"type":"text","text":"Combine Vision’s high-level APIs with Core ML to implement"},{"text":" ","type":"text"},{"text":"complex vision tasks like object detection and segmentation.","type":"text"}],"url":"\/tutorials\/higcoreml\/09-coreml-vision-integration#Object-Detection","type":"section","kind":"section","title":"Object Detection","role":"pseudoSymbol"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/06-Sound-Classification#Sound-Analysis-Framework":{"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/06-Sound-Classification#Sound-Analysis-Framework","abstract":[{"type":"text","text":"Build an app that analyzes microphone input in real-time"},{"type":"text","text":" "},{"text":"to recognize different types of sounds.","type":"text"}],"url":"\/tutorials\/higcoreml\/06-sound-classification#Sound-Analysis-Framework","type":"section","kind":"section","title":"Sound Analysis Framework","role":"pseudoSymbol"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/10-Model-Deployment#App-Store-Submission-Considerations":{"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/10-Model-Deployment#App-Store-Submission-Considerations","abstract":[{"text":"Learn strategies and best practices for managing","type":"text"},{"text":" ","type":"text"},{"text":"ML models when deploying to the App Store.","type":"text"}],"url":"\/tutorials\/higcoreml\/10-model-deployment#App-Store-Submission-Considerations","type":"section","kind":"section","title":"App Store Submission Considerations","role":"pseudoSymbol"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/07-On-Device-Training":{"type":"topic","title":"On-Device Training","kind":"project","abstract":[{"type":"text","text":"Implement personalized AI experiences by"},{"type":"text","text":" "},{"type":"text","text":"updating models directly on the user’s device."}],"url":"\/tutorials\/higcoreml\/07-on-device-training","role":"project","estimatedTime":"22min","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/07-On-Device-Training"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/08-Model-Optimization#Performance-Measurement":{"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/08-Model-Optimization#Performance-Measurement","abstract":[{"type":"text","text":"Learn optimization techniques to reduce Core ML model size"},{"type":"text","text":" "},{"type":"text","text":"and improve inference speed."}],"url":"\/tutorials\/higcoreml\/08-model-optimization#Performance-Measurement","kind":"section","type":"section","title":"Performance Measurement","role":"pseudoSymbol"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/03-Image-Classification#Vision-+-Core-ML-Integration":{"type":"section","kind":"section","abstract":[{"text":"Integrate the Vision framework with Core ML","type":"text"},{"text":" ","type":"text"},{"text":"to implement real-time image classification.","type":"text"}],"title":"Vision + Core ML Integration","url":"\/tutorials\/higcoreml\/03-image-classification#Vision-+-Core-ML-Integration","role":"pseudoSymbol","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/03-Image-Classification#Vision-+-Core-ML-Integration"},"03-request-handler.swift":{"type":"file","highlights":[],"fileName":"RequestHandler.swift","identifier":"03-request-handler.swift","content":["import Vision","import UIKit","","\/\/\/ VNImageRequestHandler로 요청 실행","\/\/\/","\/\/\/ 다양한 이미지 소스를 지원합니다.","struct RequestHandlerExamples {","    ","    \/\/ MARK: - CGImage에서","    func classifyFromCGImage(cgImage: CGImage, request: VNCoreMLRequest) throws {","        let handler = VNImageRequestHandler(","            cgImage: cgImage,","            orientation: .up,  \/\/ EXIF orientation","            options: [:]","        )","        try handler.perform([request])","    }","    ","    \/\/ MARK: - CIImage에서","    func classifyFromCIImage(ciImage: CIImage, request: VNCoreMLRequest) throws {","        let handler = VNImageRequestHandler(","            ciImage: ciImage,","            options: [:]","        )","        try handler.perform([request])","    }","    ","    \/\/ MARK: - URL에서","    func classifyFromURL(url: URL, request: VNCoreMLRequest) throws {","        let handler = VNImageRequestHandler(","            url: url,","            options: [:]","        )","        try handler.perform([request])","    }","    ","    \/\/ MARK: - Data에서","    func classifyFromData(data: Data, request: VNCoreMLRequest) throws {","        let handler = VNImageRequestHandler(","            data: data,","            options: [:]","        )","        try handler.perform([request])","    }","    ","    \/\/ MARK: - CVPixelBuffer에서 (카메라 프레임)","    func classifyFromPixelBuffer(","        pixelBuffer: CVPixelBuffer,","        request: VNCoreMLRequest","    ) throws {","        let handler = VNImageRequestHandler(","            cvPixelBuffer: pixelBuffer,","            orientation: .right,  \/\/ 카메라 방향","            options: [:]","        )","        try handler.perform([request])","    }","    ","    \/\/ MARK: - UIImage에서 (실용적인 예시)","    func classifyFromUIImage(image: UIImage, request: VNCoreMLRequest) throws {","        guard let cgImage = image.cgImage else {","            throw ClassificationError.invalidResults","        }","        ","        \/\/ UIImage의 orientation을 Vision orientation으로 변환","        let orientation = CGImagePropertyOrientation(image.imageOrientation)","        ","        let handler = VNImageRequestHandler(","            cgImage: cgImage,","            orientation: orientation,","            options: [:]","        )","        try handler.perform([request])","    }","}","","\/\/ MARK: - Orientation 변환 헬퍼","extension CGImagePropertyOrientation {","    init(_ uiOrientation: UIImage.Orientation) {","        switch uiOrientation {","        case .up: self = .up","        case .down: self = .down","        case .left: self = .left","        case .right: self = .right","        case .upMirrored: self = .upMirrored","        case .downMirrored: self = .downMirrored","        case .leftMirrored: self = .leftMirrored","        case .rightMirrored: self = .rightMirrored","        @unknown default: self = .up","        }","    }","}"],"fileType":"swift","syntax":"swift"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/07-On-Device-Training#Implementing-MLUpdateTask":{"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/07-On-Device-Training#Implementing-MLUpdateTask","abstract":[{"type":"text","text":"Implement personalized AI experiences by"},{"type":"text","text":" "},{"type":"text","text":"updating models directly on the user’s device."}],"url":"\/tutorials\/higcoreml\/07-on-device-training#Implementing-MLUpdateTask","kind":"section","type":"section","title":"Implementing MLUpdateTask","role":"pseudoSymbol"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/09-CoreML-Vision-Integration#Image-Segmentation":{"type":"section","title":"Image Segmentation","kind":"section","abstract":[{"text":"Combine Vision’s high-level APIs with Core ML to implement","type":"text"},{"type":"text","text":" "},{"text":"complex vision tasks like object detection and segmentation.","type":"text"}],"url":"\/tutorials\/higcoreml\/09-coreml-vision-integration#Image-Segmentation","role":"pseudoSymbol","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/09-CoreML-Vision-Integration#Image-Segmentation"},"03-confidence-threshold.swift":{"type":"file","highlights":[],"fileName":"ConfidenceThreshold.swift","identifier":"03-confidence-threshold.swift","content":["import Vision","","\/\/\/ 신뢰도 임계값 설정","\/\/\/","\/\/\/ 너무 낮은 신뢰도는 \"알 수 없음\"으로 처리","struct ConfidenceThreshold {","    ","    \/\/\/ 기본 임계값 (50%)","    static let defaultThreshold: Float = 0.5","    ","    \/\/\/ 엄격한 임계값 (80%)","    static let strictThreshold: Float = 0.8","    ","    \/\/\/ 느슨한 임계값 (30%)","    static let looseThreshold: Float = 0.3","    ","    \/\/\/ 임계값 기반 결과 판정","    static func evaluate(","        observations: [VNClassificationObservation],","        threshold: Float = defaultThreshold","    ) -> ClassificationDecision {","        guard let top = observations.first else {","            return .noResult","        }","        ","        if top.confidence >= strictThreshold {","            return .confident(","                label: top.identifier,","                confidence: top.confidence","            )","        } else if top.confidence >= threshold {","            return .uncertain(","                label: top.identifier,","                confidence: top.confidence,","                alternatives: Array(observations.dropFirst().prefix(3))","            )","        } else {","            return .unknown(","                topGuess: top.identifier,","                confidence: top.confidence","            )","        }","    }","}","","\/\/\/ 분류 결정 타입","enum ClassificationDecision {","    \/\/\/ 충분히 확신 (80% 이상)","    case confident(label: String, confidence: Float)","    ","    \/\/\/ 불확실하지만 유효 (50~80%)","    case uncertain(","        label: String,","        confidence: Float,","        alternatives: [VNClassificationObservation]","    )","    ","    \/\/\/ 알 수 없음 (50% 미만)","    case unknown(topGuess: String, confidence: Float)","    ","    \/\/\/ 결과 없음","    case noResult","    ","    \/\/\/ 사용자에게 표시할 메시지","    var displayMessage: String {","        switch self {","        case .confident(let label, let confidence):","            return \"\\(label) (\\(String(format: \"%.0f%%\", confidence * 100)))\"","            ","        case .uncertain(let label, let confidence, let alternatives):","            let alts = alternatives.map { $0.identifier }.joined(separator: \", \")","            return \"\\(label)? (\\(String(format: \"%.0f%%\", confidence * 100)))\\n다른 후보: \\(alts)\"","            ","        case .unknown(let topGuess, let confidence):","            return \"확실하지 않음 (최상위 추측: \\(topGuess) \\(String(format: \"%.0f%%\", confidence * 100)))\"","            ","        case .noResult:","            return \"분류 결과가 없습니다\"","        }","    }","    ","    \/\/\/ 아이콘","    var icon: String {","        switch self {","        case .confident: return \"checkmark.circle.fill\"","        case .uncertain: return \"questionmark.circle.fill\"","        case .unknown: return \"exclamationmark.triangle.fill\"","        case .noResult: return \"xmark.circle.fill\"","        }","    }","}"],"fileType":"swift","syntax":"swift"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/03-Image-Classification#Parsing-Results":{"type":"section","kind":"section","abstract":[{"text":"Integrate the Vision framework with Core ML","type":"text"},{"type":"text","text":" "},{"text":"to implement real-time image classification.","type":"text"}],"url":"\/tutorials\/higcoreml\/03-image-classification#Parsing-Results","title":"Parsing Results","role":"pseudoSymbol","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/03-Image-Classification#Parsing-Results"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/10-Model-Deployment#Compiled-Model-Management":{"type":"section","title":"Compiled Model Management","abstract":[{"type":"text","text":"Learn strategies and best practices for managing"},{"type":"text","text":" "},{"type":"text","text":"ML models when deploying to the App Store."}],"kind":"section","url":"\/tutorials\/higcoreml\/10-model-deployment#Compiled-Model-Management","role":"pseudoSymbol","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/10-Model-Deployment#Compiled-Model-Management"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/06-Sound-Classification#Custom-Sound-Classifier":{"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/06-Sound-Classification#Custom-Sound-Classifier","abstract":[{"type":"text","text":"Build an app that analyzes microphone input in real-time"},{"type":"text","text":" "},{"type":"text","text":"to recognize different types of sounds."}],"url":"\/tutorials\/higcoreml\/06-sound-classification#Custom-Sound-Classifier","type":"section","kind":"section","title":"Custom Sound Classifier","role":"pseudoSymbol"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/08-Model-Optimization":{"type":"topic","title":"Model Optimization & Compression","kind":"project","abstract":[{"type":"text","text":"Learn optimization techniques to reduce Core ML model size"},{"type":"text","text":" "},{"type":"text","text":"and improve inference speed."}],"url":"\/tutorials\/higcoreml\/08-model-optimization","role":"project","estimatedTime":"18min","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/08-Model-Optimization"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/04-Create-ML-Custom-Model":{"type":"topic","title":"Creating Custom Models with Create ML","kind":"project","abstract":[{"text":"Use Apple’s Create ML app to","type":"text"},{"text":" ","type":"text"},{"text":"train your own image classification model.","type":"text"}],"url":"\/tutorials\/higcoreml\/04-create-ml-custom-model","role":"project","estimatedTime":"25min","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/04-Create-ML-Custom-Model"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/07-On-Device-Training#Creating-Updatable-Models":{"type":"section","title":"Creating Updatable Models","abstract":[{"type":"text","text":"Implement personalized AI experiences by"},{"type":"text","text":" "},{"type":"text","text":"updating models directly on the user’s device."}],"kind":"section","url":"\/tutorials\/higcoreml\/07-on-device-training#Creating-Updatable-Models","role":"pseudoSymbol","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/07-On-Device-Training#Creating-Updatable-Models"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/04-Create-ML-Custom-Model#Check-Your-Understanding":{"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/04-Create-ML-Custom-Model#Check-Your-Understanding","titleInlineContent":[{"text":"Check Your Understanding","type":"text"}],"url":"\/tutorials\/higcoreml\/04-create-ml-custom-model#Check-Your-Understanding","title":"Check Your Understanding","type":"link"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/01-CoreML-Introduction#Project-Setup":{"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/01-CoreML-Introduction#Project-Setup","abstract":[{"type":"text","text":"Understand Apple’s machine learning framework Core ML,"},{"type":"text","text":" "},{"type":"text","text":"and learn about the benefits and use cases of on-device AI."}],"url":"\/tutorials\/higcoreml\/01-coreml-introduction#Project-Setup","kind":"section","type":"section","title":"Project Setup","role":"pseudoSymbol"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/08-Model-Optimization#Quantization":{"type":"section","title":"Quantization","abstract":[{"type":"text","text":"Learn optimization techniques to reduce Core ML model size"},{"text":" ","type":"text"},{"text":"and improve inference speed.","type":"text"}],"kind":"section","url":"\/tutorials\/higcoreml\/08-model-optimization#Quantization","role":"pseudoSymbol","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/08-Model-Optimization#Quantization"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/01-CoreML-Introduction":{"type":"topic","title":"Introduction to Core ML & On-Device ML","abstract":[{"text":"Understand Apple’s machine learning framework Core ML,","type":"text"},{"text":" ","type":"text"},{"text":"and learn about the benefits and use cases of on-device AI.","type":"text"}],"kind":"project","url":"\/tutorials\/higcoreml\/01-coreml-introduction","role":"project","estimatedTime":"15min","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/01-CoreML-Introduction"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/06-Sound-Classification#Sound-Classification-UI":{"abstract":[{"type":"text","text":"Build an app that analyzes microphone input in real-time"},{"type":"text","text":" "},{"type":"text","text":"to recognize different types of sounds."}],"kind":"section","type":"section","url":"\/tutorials\/higcoreml\/06-sound-classification#Sound-Classification-UI","title":"Sound Classification UI","role":"pseudoSymbol","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/06-Sound-Classification#Sound-Classification-UI"},"doc://coreml.HIGCoreML/tutorials/Table-of-Contents":{"type":"topic","title":"Building an Image Classification App with Core ML","kind":"overview","abstract":[{"type":"text","text":"Learn to build a working AI image classification app"},{"text":" ","type":"text"},{"type":"text","text":"using Apple’s on-device machine learning framework, Core ML."}],"url":"\/tutorials\/table-of-contents","role":"overview","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/Table-of-Contents"},"03-result-parsing.swift":{"type":"file","highlights":[],"fileName":"ResultParsing.swift","identifier":"03-result-parsing.swift","content":["import Vision","","\/\/\/ 분류 결과 파싱","\/\/\/","\/\/\/ VNClassificationObservation 배열에서 유용한 정보를 추출","struct ResultParser {","    ","    \/\/\/ 상위 N개 결과 추출","    func topResults(","        from observations: [VNClassificationObservation],","        count: Int = 5","    ) -> [Classification] {","        observations","            .sorted { $0.confidence > $1.confidence }","            .prefix(count)","            .map { Classification(label: $0.identifier, confidence: $0.confidence) }","    }","    ","    \/\/\/ 최상위 결과만 추출","    func topResult(from observations: [VNClassificationObservation]) -> Classification? {","        guard let top = observations.max(by: { $0.confidence < $1.confidence }) else {","            return nil","        }","        return Classification(label: top.identifier, confidence: top.confidence)","    }","    ","    \/\/\/ 임계값 이상인 결과만 필터링","    func validResults(","        from observations: [VNClassificationObservation],","        threshold: Float = 0.5","    ) -> [Classification] {","        observations","            .filter { $0.confidence >= threshold }","            .sorted { $0.confidence > $1.confidence }","            .map { Classification(label: $0.identifier, confidence: $0.confidence) }","    }","    ","    \/\/\/ 특정 레이블 검색","    func findLabel(","        _ label: String,","        in observations: [VNClassificationObservation]","    ) -> Classification? {","        guard let observation = observations.first(where: {","            $0.identifier.lowercased().contains(label.lowercased())","        }) else {","            return nil","        }","        return Classification(label: observation.identifier, confidence: observation.confidence)","    }","    ","    \/\/\/ 레이블 그룹별 합계 (카테고리 집계용)","    func groupedConfidence(","        for keywords: [String],","        in observations: [VNClassificationObservation]","    ) -> Float {","        observations","            .filter { observation in","                keywords.contains { keyword in","                    observation.identifier.lowercased().contains(keyword.lowercased())","                }","            }","            .reduce(0) { $0 + $1.confidence }","    }","}","","\/\/ MARK: - 사용 예시","extension ResultParser {","    ","    \/\/\/ \"강아지 종류\" 인지 확인","    func isDog(observations: [VNClassificationObservation]) -> (isDog: Bool, confidence: Float) {","        let dogKeywords = [\"dog\", \"retriever\", \"terrier\", \"spaniel\", \"poodle\", \"bulldog\"]","        let confidence = groupedConfidence(for: dogKeywords, in: observations)","        return (confidence > 0.5, confidence)","    }","    ","    \/\/\/ \"음식\" 인지 확인","    func isFood(observations: [VNClassificationObservation]) -> (isFood: Bool, confidence: Float) {","        let foodKeywords = [\"pizza\", \"burger\", \"sushi\", \"cake\", \"salad\", \"soup\"]","        let confidence = groupedConfidence(for: foodKeywords, in: observations)","        return (confidence > 0.5, confidence)","    }","}"],"fileType":"swift","syntax":"swift"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/01-CoreML-Introduction#What-is-Core-ML":{"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/01-CoreML-Introduction#What-is-Core-ML","abstract":[{"type":"text","text":"Understand Apple’s machine learning framework Core ML,"},{"type":"text","text":" "},{"type":"text","text":"and learn about the benefits and use cases of on-device AI."}],"kind":"section","type":"section","url":"\/tutorials\/higcoreml\/01-coreml-introduction#What-is-Core-ML","title":"What is Core ML?","role":"pseudoSymbol"},"doc://coreml.HIGCoreML/tutorials/Table-of-Contents/Part-5:-Integration-&-Deployment":{"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/Table-of-Contents\/Part-5:-Integration-&-Deployment","abstract":[],"url":"\/tutorials\/table-of-contents\/part-5:-integration-&-deployment","type":"topic","kind":"article","title":"Part 5: Integration & Deployment","role":"article"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/03-Image-Classification":{"type":"topic","title":"Image Classification (VNCoreMLRequest)","abstract":[{"text":"Integrate the Vision framework with Core ML","type":"text"},{"text":" ","type":"text"},{"type":"text","text":"to implement real-time image classification."}],"kind":"project","url":"\/tutorials\/higcoreml\/03-image-classification","role":"project","estimatedTime":"20min","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/03-Image-Classification"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/02-Loading-MLModel#ImageClassifier-Service":{"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/02-Loading-MLModel#ImageClassifier-Service","abstract":[{"type":"text","text":"Learn how to add .mlmodel files to your project"},{"type":"text","text":" "},{"type":"text","text":"and load and use models in Swift."}],"url":"\/tutorials\/higcoreml\/02-loading-mlmodel#ImageClassifier-Service","kind":"section","type":"section","title":"ImageClassifier Service","role":"pseudoSymbol"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/04-Create-ML-Custom-Model#Introduction-to-Create-ML":{"type":"section","title":"Introduction to Create ML","abstract":[{"type":"text","text":"Use Apple’s Create ML app to"},{"type":"text","text":" "},{"type":"text","text":"train your own image classification model."}],"kind":"section","url":"\/tutorials\/higcoreml\/04-create-ml-custom-model#Introduction-to-Create-ML","role":"pseudoSymbol","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/04-Create-ML-Custom-Model#Introduction-to-Create-ML"},"doc://coreml.HIGCoreML/tutorials/Table-of-Contents/Part-2:-Image-Classification":{"type":"topic","abstract":[],"kind":"article","title":"Part 2: Image Classification","url":"\/tutorials\/table-of-contents\/part-2:-image-classification","role":"article","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/Table-of-Contents\/Part-2:-Image-Classification"},"doc://coreml.HIGCoreML/tutorials/Table-of-Contents/Part-4:-Advanced-Features":{"abstract":[],"type":"topic","kind":"article","url":"\/tutorials\/table-of-contents\/part-4:-advanced-features","title":"Part 4: Advanced Features","role":"article","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/Table-of-Contents\/Part-4:-Advanced-Features"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/08-Model-Optimization#Why-Optimization-is-Needed":{"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/08-Model-Optimization#Why-Optimization-is-Needed","abstract":[{"type":"text","text":"Learn optimization techniques to reduce Core ML model size"},{"type":"text","text":" "},{"type":"text","text":"and improve inference speed."}],"url":"\/tutorials\/higcoreml\/08-model-optimization#Why-Optimization-is-Needed","type":"section","kind":"section","title":"Why Optimization is Needed","role":"pseudoSymbol"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/06-Sound-Classification#Check-Your-Understanding":{"url":"\/tutorials\/higcoreml\/06-sound-classification#Check-Your-Understanding","type":"link","titleInlineContent":[{"text":"Check Your Understanding","type":"text"}],"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/06-Sound-Classification#Check-Your-Understanding","title":"Check Your Understanding"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/02-Loading-MLModel#Adding-an-MLModel":{"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/02-Loading-MLModel#Adding-an-MLModel","abstract":[{"type":"text","text":"Learn how to add .mlmodel files to your project"},{"text":" ","type":"text"},{"type":"text","text":"and load and use models in Swift."}],"url":"\/tutorials\/higcoreml\/02-loading-mlmodel#Adding-an-MLModel","type":"section","kind":"section","title":"Adding an MLModel","role":"pseudoSymbol"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/05-Text-Classification#Check-Your-Understanding":{"title":"Check Your Understanding","type":"link","url":"\/tutorials\/higcoreml\/05-text-classification#Check-Your-Understanding","titleInlineContent":[{"text":"Check Your Understanding","type":"text"}],"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/05-Text-Classification#Check-Your-Understanding"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/02-Loading-MLModel":{"type":"topic","title":"Loading & Using MLModel","kind":"project","abstract":[{"text":"Learn how to add .mlmodel files to your project","type":"text"},{"type":"text","text":" "},{"text":"and load and use models in Swift.","type":"text"}],"url":"\/tutorials\/higcoreml\/02-loading-mlmodel","role":"project","estimatedTime":"12min","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/02-Loading-MLModel"},"03-result-model.swift":{"type":"file","highlights":[],"fileName":"ClassificationResult.swift","identifier":"03-result-model.swift","content":["import Vision","import Foundation","","\/\/\/ 분류 결과 모델","\/\/\/","\/\/\/ VNClassificationObservation을 앱에서 사용하기 쉬운 형태로 변환","struct ImageClassificationResult: Identifiable {","    let id = UUID()","    ","    \/\/\/ 최상위 분류 레이블","    let topLabel: String","    ","    \/\/\/ 최상위 분류 신뢰도 (0.0 ~ 1.0)","    let topConfidence: Float","    ","    \/\/\/ 상위 N개 결과","    let topResults: [Classification]","    ","    \/\/\/ 분류 시간","    let classificationTime: TimeInterval","    ","    \/\/\/ 유효한 결과인지 (신뢰도 임계값 기준)","    var isValid: Bool {","        topConfidence >= 0.5  \/\/ 50% 이상","    }","    ","    \/\/\/ 신뢰도 퍼센트 문자열","    var confidenceText: String {","        String(format: \"%.1f%%\", topConfidence * 100)","    }","}","","\/\/\/ 개별 분류 항목","struct Classification: Identifiable {","    let id = UUID()","    let label: String","    let confidence: Float","    ","    var confidenceText: String {","        String(format: \"%.1f%%\", confidence * 100)","    }","    ","    \/\/\/ 신뢰도를 0~1 범위의 Progress로","    var progress: Double {","        Double(confidence)","    }","}","","\/\/ MARK: - VNClassificationObservation 변환","extension ImageClassificationResult {","    ","    \/\/\/ VNClassificationObservation 배열에서 결과 생성","    init(from observations: [VNClassificationObservation], time: TimeInterval = 0) {","        let sorted = observations.sorted { $0.confidence > $1.confidence }","        ","        self.topLabel = sorted.first?.identifier ?? \"알 수 없음\"","        self.topConfidence = sorted.first?.confidence ?? 0","        self.topResults = sorted.prefix(5).map { observation in","            Classification(","                label: observation.identifier,","                confidence: observation.confidence","            )","        }","        self.classificationTime = time","    }","}","","\/\/ MARK: - Preview Data","extension ImageClassificationResult {","    static let preview = ImageClassificationResult(","        topLabel: \"Golden Retriever\",","        topConfidence: 0.923,","        topResults: [","            Classification(label: \"Golden Retriever\", confidence: 0.923),","            Classification(label: \"Labrador Retriever\", confidence: 0.045),","            Classification(label: \"Cocker Spaniel\", confidence: 0.012),","            Classification(label: \"Irish Setter\", confidence: 0.008),","            Classification(label: \"Beagle\", confidence: 0.005)","        ],","        classificationTime: 0.023","    )","}"],"fileType":"swift","syntax":"swift"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/03-Image-Classification#UI-Integration":{"type":"section","abstract":[{"type":"text","text":"Integrate the Vision framework with Core ML"},{"type":"text","text":" "},{"type":"text","text":"to implement real-time image classification."}],"kind":"section","title":"UI Integration","url":"\/tutorials\/higcoreml\/03-image-classification#UI-Integration","role":"pseudoSymbol","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/03-Image-Classification#UI-Integration"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/08-Model-Optimization#Palettization":{"type":"section","kind":"section","abstract":[{"type":"text","text":"Learn optimization techniques to reduce Core ML model size"},{"type":"text","text":" "},{"type":"text","text":"and improve inference speed."}],"title":"Palettization","url":"\/tutorials\/higcoreml\/08-model-optimization#Palettization","role":"pseudoSymbol","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/08-Model-Optimization#Palettization"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/08-Model-Optimization#Check-Your-Understanding":{"title":"Check Your Understanding","type":"link","url":"\/tutorials\/higcoreml\/08-model-optimization#Check-Your-Understanding","titleInlineContent":[{"text":"Check Your Understanding","type":"text"}],"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/08-Model-Optimization#Check-Your-Understanding"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/10-Model-Deployment":{"type":"topic","title":"Model Management for App Deployment","abstract":[{"text":"Learn strategies and best practices for managing","type":"text"},{"type":"text","text":" "},{"type":"text","text":"ML models when deploying to the App Store."}],"kind":"project","url":"\/tutorials\/higcoreml\/10-model-deployment","role":"project","estimatedTime":"15min","identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/10-Model-Deployment"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/01-CoreML-Introduction#Check-Your-Understanding":{"title":"Check Your Understanding","titleInlineContent":[{"type":"text","text":"Check Your Understanding"}],"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/01-CoreML-Introduction#Check-Your-Understanding","url":"\/tutorials\/higcoreml\/01-coreml-introduction#Check-Your-Understanding","type":"link"},"doc://coreml.HIGCoreML/tutorials/HIGCoreML/07-On-Device-Training#Understanding-On-Device-Training":{"identifier":"doc:\/\/coreml.HIGCoreML\/tutorials\/HIGCoreML\/07-On-Device-Training#Understanding-On-Device-Training","abstract":[{"type":"text","text":"Implement personalized AI experiences by"},{"type":"text","text":" "},{"type":"text","text":"updating models directly on the user’s device."}],"url":"\/tutorials\/higcoreml\/07-on-device-training#Understanding-On-Device-Training","type":"section","kind":"section","title":"Understanding On-Device Training","role":"pseudoSymbol"}}}